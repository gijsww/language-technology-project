{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "from model import gan\n",
    "from early_stopping import EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "# Unique Naming\n",
    "from datetime import datetime\n",
    "import random, string\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_string(length=10):\n",
    "    \"\"\"\n",
    "        Generate a random string of given length. For safely storing produced images.\n",
    "    \"\"\"\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "\n",
    "def get_model_id():\n",
    "    \"\"\"\n",
    "        Creates folder with unique ID in which everything related to a particular testrun can be saved.\n",
    "    :return: Unique folder identifier\n",
    "    \"\"\"\n",
    "    # Construct testrun identifier\n",
    "    TIME_STAMP = datetime.now().strftime(\"%Y_%d_%m__%H_%M_%S__%f_\")\n",
    "    model_folder_id = TIME_STAMP + '_' + random_string() + '/'\n",
    "\n",
    "    try:\n",
    "        os.makedirs(model_folder_id)\n",
    "    except Exception as e:\n",
    "        print('Exception occurred: ', e)\n",
    "\n",
    "    return model_folder_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES & ADMINISTRATIVE STUFF ###\n",
    "# System\n",
    "dataset_path = '/media/daniel/Elements/FastText_Data/'  # In case dataset is stored somewhere else, e.g. on hard-drive\n",
    "#dataset_path = ''  # Data in same directory\n",
    "dictionary_path = '/media/daniel/Elements/FastText_Data/'  # Dictionaries in same directory\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Network\n",
    "embedding_dim = 300\n",
    "internal_dim = 300\n",
    "output_dim = 2\n",
    "\n",
    "# Train hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "vocab_size = 5000\n",
    "num_minibatches = vocab_size // batch_size\n",
    "real_label, fake_label = 1, 0\n",
    "languages = {'src': ['de']  #, 'nl'\n",
    "             , 'trgt': ['en']}  # Target language to be indicated in last position\n",
    "checkpoint_frequency = 0  # 0 == Off; i > 0 == actual checkpoint frequency in epochs\n",
    "avg_grads = False  # Boolean indicating whether to average the grads of decoder & discriminator accumulated over nr of source languages by nr of source langs\n",
    "early_stop = False # Boolean indicating whether to stop early if loss won't decrease for a certain threshold\n",
    "eval_frequency = 10\n",
    "\n",
    "gan_mode = 'linear'  # vs. 'nonlinear'\n",
    "#testing parameters\n",
    "N = [1] # List of n nearest neighbors that will be performed in evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: ./2020_10_06__15_55_09__910815__fabtxatdgl/Final/\n",
      "Model ID: 2020_10_06__15_55_09__910815__fabtxatdgl/\n"
     ]
    }
   ],
   "source": [
    "# Set up saving paths\n",
    "data_storage_path = './'\n",
    "model_id = get_model_id()\n",
    "checkpoint_path = data_storage_path + model_id + 'Checkpoint/'\n",
    "final_state_path = data_storage_path + model_id + 'Final/'\n",
    "\n",
    "try:\n",
    "    if checkpoint_frequency > 0:\n",
    "        os.makedirs(checkpoint_path)\n",
    "        print('Created:', checkpoint_path)\n",
    "    os.makedirs(final_state_path)\n",
    "    print('Created:', final_state_path)\n",
    "except Exception as e:\n",
    "    raise Warning('Exception occurred: Cound not create dirs! Exception:', e)\n",
    "    \n",
    "print('Model ID:', model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_vocab(vocab):\n",
    "    # Returns the word embeddings and matching labels for the full vocabulary\n",
    "    words = vocab.words\n",
    "    vectors = [vocab[word] for word in words]\n",
    "    return vectors, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_vocab(vocab, vocab_size):\n",
    "    # Remove all punctuation tokens while valid nr of tokens is insufficient yet for having full vocab size\n",
    "    # TODO & possibly reserve testing vocab\n",
    "    # Return clean & restricted vocab\n",
    "    words = vocab.words[:vocab_size]              # Y (labels)\n",
    "    vects = [vocab[word] for word in words]       # X (input data)\n",
    "\n",
    "    return vects, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lang_to_vocab(lang_id, vocab_size, vocabs, full_vocabs):\n",
    "    # Get dataset\n",
    "    if dataset_path == './':\n",
    "        fasttext.util.download_model(lang_id)  # Download word embedding vector data if not available\n",
    "    vocab = fasttext.load_model(dataset_path + 'cc.' + lang_id + '.300.bin')  # Load language data\n",
    "\n",
    "    # Add train data (embedding-vectors) and labels (words) to vocab\n",
    "    X, Y = cleaned_vocab(vocab,500000)\n",
    "    x, y = cleaned_vocab(vocab, vocab_size)\n",
    "    vocabs[lang_id] = {'x': torch.tensor(x), 'y': y}\n",
    "    full_vocabs[lang_id] = {'X': X, 'Y': Y}\n",
    "\n",
    "    return vocabs, full_vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(languages):\n",
    "    vocabs = {}\n",
    "    full_vocabs = {}\n",
    "    \n",
    "    for language in languages['src']+languages['trgt']:\n",
    "        vocabs, full_vocabs = add_lang_to_vocab(language, vocab_size, vocabs, full_vocabs)\n",
    "\n",
    "    print('Successfully loaded language models.')\n",
    "    return vocabs, full_vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded language models.\n"
     ]
    }
   ],
   "source": [
    "#load vocab (keep in independent cell for bugfixing purposes)\n",
    "vocabs, full_vocabs = load_vocab(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocabs = {}\n",
    "source_full_vocabs = {}\n",
    "\n",
    "for source_language in languages['src']:\n",
    "    source_vocabs[source_language] = vocabs[source_language]\n",
    "    source_full_vocabs[source_language] = full_vocabs[source_language]\n",
    "target_full_vocabs = full_vocabs[languages['trgt'][0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dictionary(dictionary_text):\n",
    "    # Converts an input dictionary text file to a python dictionary\n",
    "    dictionary = {}\n",
    "    source = True\n",
    "    source_word = ''\n",
    "    target_word = ''\n",
    "    \n",
    "    for character in dictionary_text:\n",
    "        if source is True:\n",
    "            if character is '\\t' or character is ' ':\n",
    "                source = False\n",
    "            else:\n",
    "                source_word = source_word + character\n",
    "        else:\n",
    "            if character is '\\n':\n",
    "                source = True\n",
    "                if source_word in dictionary:\n",
    "                    dictionary[source_word].append(target_word)\n",
    "                else:\n",
    "                    dictionary[source_word] = [target_word]\n",
    "                source_word = ''\n",
    "                target_word = ''\n",
    "            else:\n",
    "                target_word = target_word + character\n",
    "                \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionaries(languages):\n",
    "    # Loads in the bilingual dictionaries\n",
    "    dictionaries = {}\n",
    "    \n",
    "    for source_language in languages['src']:\n",
    "        file = open(dictionary_path + source_language + '-' + languages['trgt'][0] + '.txt', 'r', errors='ignore')\n",
    "        dictionary_text = file.read()\n",
    "        dictionaries[source_language] = convert_dictionary(dictionary_text)\n",
    "    \n",
    "    return dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_translation_task(languages, source_full_vocabs, dictionaries):\n",
    "    # Creates a split in eval and training translation task\n",
    "    eval_words = {}\n",
    "    test_words = {}\n",
    "    \n",
    "    for source_language in languages['src']:\n",
    "        source_words = list(dictionaries[source_language].keys())\n",
    "#         random.shuffle(source_words)\n",
    "        eval_list = []\n",
    "        for source_word in source_words:\n",
    "            if source_word in source_full_vocabs[source_language]['Y']:\n",
    "                eval_list.append(source_word)\n",
    "            if len(eval_list) is 200:\n",
    "                eval_words[source_language] = eval_list\n",
    "                break\n",
    "#             eval_words[source_language] = source_words[0:50]\n",
    "#             test_words[source_language] = source_words[50:150]        \n",
    "#         eval_words[source_language] = source_words[0:int(len(source_words)/2)]\n",
    "#         test_words[source_language] = source_words[int(len(source_words)/2):len(source_words)]\n",
    "        \n",
    "    return eval_words, test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in dictionaries (independent cell for bugfixing)\n",
    "dictionaries = load_dictionaries(languages)\n",
    "\n",
    "# split in train and evaluation\n",
    "eval_words, test_words = split_translation_task(languages, source_full_vocabs, dictionaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbor fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_neighbors(N, languages, full_vocabs):\n",
    "    target_neighbors = {}\n",
    "    \n",
    "    for n in N:\n",
    "        target_neighbors[n] = NearestNeighbors(n_neighbors=n, metric='cosine').fit(full_vocabs[languages['trgt'][0]]['X'])\n",
    "        \n",
    "    return target_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = fit_neighbors(N, languages, full_vocabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine(vector1, vector2):\n",
    "    # Computes the cosine simularity between two vectors\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_vector1 = np.linalg.norm(vector1)\n",
    "    norm_vector2 = np.linalg.norm(vector2)\n",
    "    return dot_product/(norm_vector1*norm_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_translations(generator, language, source_vector, target_vocab, neighbors):\n",
    "    # Gets n possible translations, as given by the n nearest neighbors of the transformed\n",
    "    # source vector in the target embeddings space, we will use a package for this for optimization\n",
    "    # purposes. n is given in the nearest neighbor fitting stage.\n",
    "    #print(source_vector.numpy()[0])\n",
    "    transformed_source_embedding = generator(torch.as_tensor(source_vector), language).detach().numpy()\n",
    "\n",
    "    # only takes 2D arrays, hence the extra bracket [1][0] stands for select indices of\n",
    "    # the first input vector (the only one in this case)\n",
    "\n",
    "    vocab_indices = neighbors.kneighbors(np.array([transformed_source_embedding]))[1][0]\n",
    "    target_vectors = []\n",
    "    target_words = []\n",
    "    for index in vocab_indices:\n",
    "        target_vectors.append(target_vocab['X'][index])\n",
    "        target_words.append(target_vocab['Y'][index])\n",
    "\n",
    "    return target_vectors, target_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_translations_batch(generator, language, source_vectors, target_vocab, neighbors):\n",
    "    # Gets n possible translations, as given by the n nearest neighbors of the transformed\n",
    "    # source vector in the target embeddings space, we will use a package for this for optimization\n",
    "    # purposes. n is given in the nearest neighbor fitting stage.\n",
    "    #print(source_vector.numpy()[0])\n",
    "    if gan_mode is 'nonlinear':\n",
    "        transformed_source_embedding = generator(torch.as_tensor(source_vectors), language).detach().numpy()\n",
    "    elif gan_mode is 'linear':\n",
    "        transformed_source_embedding = generator(torch.as_tensor(source_vectors)).detach().numpy()\n",
    "\n",
    "    # only takes 2D arrays, hence the extra bracket [1][0] stands for select indices of\n",
    "    # the first input vector (the only one in this case)\n",
    "\n",
    "    vocab_indices = neighbors.kneighbors(np.array(transformed_source_embedding))[1]\n",
    "    target_vectors = []\n",
    "    target_words = []\n",
    "    for target_indices in vocab_indices:\n",
    "        vectors = []\n",
    "        words = []\n",
    "        for index in target_indices:\n",
    "            vectors.append(target_vocab['X'][index])\n",
    "            words.append(target_vocab['Y'][index])\n",
    "        target_vectors.append(vectors)\n",
    "        target_words.append(words)\n",
    "    \n",
    "    print('Target words:\\n', target_words)\n",
    "    return target_vectors, target_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_cosine(generator, language, source_word_vectors, target_vocab, neighbors):\n",
    "    # Computes the average cosine simularity between the source words and their translations\n",
    "    sum_of_cosines = 0\n",
    "    for source_word_vector in source_word_vectors[:30]:\n",
    "        translated_word_vector = get_n_translations(generator, language, source_word_vector, target_vocab, neighbors[1])[0][0]\n",
    "        sum_of_cosines += compute_cosine(source_word_vector, translated_word_vector)\n",
    "    return sum_of_cosines/len(source_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_cosine_batch(generator, language, source_word_vectors, target_vocab, neighbors):\n",
    "    # Computes the average cosine simularity between the source words and their translations\n",
    "    sum_of_cosines = 0\n",
    "    translated_word_vectors = get_n_translations_batch(generator, language, source_word_vectors, target_vocab, neighbors[1])[0]\n",
    "    for source_word_vector, translated_word_vector in zip(source_word_vectors, translated_word_vectors):\n",
    "        sum_of_cosines += compute_cosine(source_word_vector, translated_word_vector[0])\n",
    "    return sum_of_cosines/len(source_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_accuracy(generator, language, source_words, source_vocab, target_vocab, dictionary, neighbors):\n",
    "    # Compute the accuracy of translation over the given set of source words\n",
    "    correct_translations = 0\n",
    "    for source_word in source_words:\n",
    "        source_word_index = source_vocab['Y'].index(source_word)\n",
    "        source_word_vector = source_vocab['X'][source_word_index]\n",
    "        n_target_words = get_n_translations(generator, language, source_word_vector, target_vocab, neighbors)[1]\n",
    "        for target_word in n_target_words:\n",
    "            if target_word in dictionary[source_word]:\n",
    "                correct_translations += 1\n",
    "                break\n",
    "    return correct_translations/len(source_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translation_accuracy_batch(generator, language, source_words, source_vocab, target_vocab, dictionary, neighbors):\n",
    "    # Compute the accuracy of translation over the given set of source words\n",
    "    correct_translations = 0\n",
    "    source_word_vectors = []\n",
    "    for source_word in source_words:\n",
    "        source_word_index = source_vocab['Y'].index(source_word)\n",
    "        source_word_vectors.append(source_vocab['X'][source_word_index])\n",
    "    target_words = get_n_translations_batch(generator, language, source_word_vectors, target_vocab, neighbors)[1]\n",
    "    for n_target_words in target_words:\n",
    "        for target_word in n_target_words:\n",
    "            if target_word in dictionary[source_word]:\n",
    "                correct_translations += 1\n",
    "                break\n",
    "    return correct_translations/len(source_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(generator, languages, source_training_vocabs, source_eval_words, source_full_vocabs, target_full_vocabs, dictionaries, neighbors, N):\n",
    "    # Evaluates the current model by using both an unsupervised cosine similiraty metric and a \n",
    "    # supervised translation accuracy metric. We have included both to see how they compare.\n",
    "    for source_language in languages['src']:\n",
    "        cosine_metric =  get_average_cosine_batch(generator, source_language, source_training_vocabs[source_language]['x'], target_full_vocabs, neighbors) #experimental\n",
    "#         cosine_metric = ''\n",
    "        accuracy_text = 'accuracies are '\n",
    "        for n in N:\n",
    "            accuracy = get_translation_accuracy_batch(generator, source_language, source_eval_words[source_language], source_full_vocabs[source_language], target_full_vocabs, dictionaries[source_language], neighbors[n])\n",
    "            accuracy_text = str(accuracy_text) + 'p@' + str(n) + '=' + str(accuracy) + ', '\n",
    "        \n",
    "        print('evaluation of source language ' + source_language + ': average cosine=',cosine_metric, accuracy_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(generator, languages, source_test_words, source_full_vocabs, target_full_vocabs, dictionaries, neighbors, N):\n",
    "    # Testing based on translation accuracy on testing set\n",
    "    for source_language in languages['src']:\n",
    "        accuracy_text = ''\n",
    "        for n in N:\n",
    "            accuracy = get_translation_accuracy_batch(generator, source_language, source_test_words[source_language], source_full_vocabs[source_language], target_full_vocabs, dictionaries[source_language], neighbors[n])\n",
    "            accuracy_text = accuracy_text + 'p@' + n + '=' + accuracy + ', '\n",
    "        \n",
    "        print('Testing accuracies of source language ' + source_language + \": \" + accuracy_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(data, save):\n",
    "    if save:\n",
    "        torch.save(data, checkpoint_path + 'checkpoint_%d.pt' % data['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_param(model):\n",
    "    return torch.mean(torch.cat([param.data.view(-1) for param in model.parameters()], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_sample(lang, vocab, batch_size, include_y=False):\n",
    "    \"\"\"\n",
    "    This function draws batch_size-many training samples at random \n",
    "    from a vocab corresponding to queried language.  \n",
    "    \"\"\"\n",
    "    indices = torch.LongTensor(batch_size).random_(0, len(vocab))\n",
    "    if include_y:\n",
    "        return vocab['x'][indices], vocab['y'][indices]\n",
    "    return vocab['x'][indices]\n",
    "\n",
    "\n",
    "def get_train_data(languages, vocabs, batch_size, include_y=False):\n",
    "    \"\"\"\n",
    "    Returns one set of samples datapoints form a vocabulary for each provided language.\n",
    "    \"\"\"\n",
    "    x, y = {}, {}\n",
    "    \n",
    "    # Source languages\n",
    "    for lang in languages['src']+languages['trgt']:\n",
    "        if include_y:\n",
    "            x[lang], y[lang] = get_dataset_sample(lang, vocabs[lang], batch_size, include_y)\n",
    "        else:\n",
    "            x[lang] = get_dataset_sample(lang, vocabs[lang], batch_size)\n",
    "    \n",
    "    # Return\n",
    "    if include_y:\n",
    "        return x, y\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging - Compute sum of abs(gradients) of model\n",
    "def get_summed_abs_grads(model):\n",
    "#     summed_abs = torch.tensor(0)\n",
    "    summed_abs = 0\n",
    "    for p in model.parameters():\n",
    "        summed_abs += torch.sum(torch.abs(p))\n",
    "    return summed_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## Iterative orthogonalization procedure proposed by and adjusted from Conneau et al.\\n# (https://arxiv.org/pdf/1710.04087.pdf)\\n# (https://github.com/facebookresearch/MUSE/blob/3159355b93f5c3c4883808ba785ba9d18d7f5e81/src/trainer.py#L181)\\n\\n# Check orthogonalization\\na = torch.tensor([0.1, 5., 3., 1.1, 0.2])\\na = a / torch.sum(a)\\nb = torch.tensor([-0.1, 2.5, 5.3, 0.1, -0.2])\\nb = b / torch.sum(b)\\n\\nprint(a.dot(b))\\n\\nimportlib.reload(gan)\\nnet = gan.GAN(5, 5, 5, mode='linear')\\nprint('Weights before orthogonalization:')\\nprint(net.generator.w1.weight.data)\\n\\nfor i in range(10000):\\n    # Perform incremental orthogonalization\\n    net.generator.orthogonalize()\\n\\nprint('Weights after orthogonalization:')\\nprint(net.generator.w1.weight.data)\\n\\na_ = net.generator(a).detach()\\nb_ = net.generator(b).detach()\\n\\nprint(a_.dot(b_))\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Iterative orthogonalization procedure proposed by and adjusted from Conneau et al.\n",
    "# (https://arxiv.org/pdf/1710.04087.pdf)\n",
    "# (https://github.com/facebookresearch/MUSE/blob/3159355b93f5c3c4883808ba785ba9d18d7f5e81/src/trainer.py#L181)\n",
    "\n",
    "# Check orthogonalization\n",
    "a = torch.tensor([0.1, 5., 3., 1.1, 0.2])\n",
    "a = a / torch.sum(a)\n",
    "b = torch.tensor([-0.1, 2.5, 5.3, 0.1, -0.2])\n",
    "b = b / torch.sum(b)\n",
    "\n",
    "print(a.dot(b))\n",
    "\n",
    "importlib.reload(gan)\n",
    "net = gan.GAN(5, 5, 5, mode='linear')\n",
    "print('Weights before orthogonalization:')\n",
    "print(net.generator.w1.weight.data)\n",
    "\n",
    "for i in range(10000):\n",
    "    # Perform incremental orthogonalization\n",
    "    net.generator.orthogonalize()\n",
    "\n",
    "print('Weights after orthogonalization:')\n",
    "print(net.generator.w1.weight.data)\n",
    "\n",
    "a_ = net.generator(a).detach()\n",
    "b_ = net.generator(b).detach()\n",
    "\n",
    "print(a_.dot(b_))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr source languages: 1\n",
      "Nr target languages: 1\n",
      "\n",
      " {'trgt': ['en'], 'src': ['de']}\n",
      "GAN: Linear mode chosen!\n",
      "Linear...\n",
      "Epoch  0 / 100\n",
      "Progress:  267.65802 69.04177\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 5072.008\n",
      "Epoch  1 / 100\n",
      "Progress:  581.14795 5.8958583\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 3198.0752\n",
      "Epoch  2 / 100\n",
      "Progress:  624.50433 3.4960315\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 2033.8228\n",
      "Epoch  3 / 100\n",
      "Progress:  654.1113 2.8425114\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 1367.2162\n",
      "Epoch  4 / 100\n",
      "Progress:  674.62854 2.467994\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 1009.7919\n",
      "Epoch  5 / 100\n",
      "Progress:  688.6425 2.2394235\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 829.1099\n",
      "Epoch  6 / 100\n",
      "Progress:  697.75037 2.110925\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 744.02057\n",
      "Epoch  7 / 100\n",
      "Progress:  704.0521 2.0179455\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 702.072\n",
      "Epoch  8 / 100\n",
      "Progress:  707.03094 1.9682604\n",
      "Summed abs weights Generator: 4310.838\n",
      "Summed abs weights Discrimi.: 681.8944\n",
      "Epoch  9 / 100\n",
      "Progress:  710.2791 1.9384112\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 670.74115\n",
      "Epoch  10 / 100\n",
      "Progress:  711.38556 1.9203826\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 664.83746\n",
      "Target words:\n",
      " [['GAGE'], ['ListingsContestsCommunityConnect'], ['OEP'], ['grieve'], ['Amathus'], ['Newcomer'], ['Zumbo'], ['re-capture'], ['LDS'], ['influence'], ['SPENDING'], ['Kallista'], ['Jumpin'], ['DINING'], ['ProgramPosted'], ['AHPRA'], ['CSRA'], ['Neoclassic'], ['Coty'], ['Valade'], ['fierceness'], ['Durdle'], ['50,800'], ['CareLifestyle'], ['use-by'], ['Period'], ['Lumbarda'], ['fapdu.com'], ['modeling'], ['scorn'], ['Suja'], ['plugin.Translate'], ['medaled'], ['embrace'], ['Learnership'], ['NYNY'], ['Heitkamp'], ['billboards'], ['Prekindergarten'], ['Newcomer'], ['Biglari'], ['immersion'], ['glowed'], ['cardiology'], ['Brandilyn'], ['Caffe'], ['Cuppa'], ['OLYMPUS'], ['Blundstone'], ['admires'], ['DECA'], ['ProgramPosted'], ['Methodology'], ['Surveyed'], ['replyComment'], ['Lumbarda'], ['InstagramPinterestTwitter'], ['Lumbarda'], ['Ingela'], ['mercruiser'], ['Thee'], ['Booklovers'], ['moxy'], ['1,792'], ['VOM'], ['bikin'], ['Diosa'], ['Embrace'], ['Spectrophotometers'], ['GAGE'], ['Abbott'], ['Claflin'], ['DKI'], ['Lampanelli'], ['Sevigny'], ['Camerota'], ['.410'], ['McLane'], ['marksmanship'], ['Kally'], ['Pando'], ['11am-7pm'], ['Fadi'], ['McLane'], ['MaxCDN'], ['Babel'], ['Chocoholic'], ['Keithley'], ['flextime'], ['nique'], ['flatwater'], ['Steinle'], ['pty'], ['Kally'], ['titer'], ['Maaji'], ['annointing'], ['Valade'], ['FindRealJob.in'], ['AWANA'], ['Introvert'], ['2hrs'], ['Newcomer'], ['Wynns'], ['Lingle'], ['Rell'], ['cross-trained'], ['broadened'], ['Smiled'], ['freelances'], ['Swimwear'], ['Taffy'], ['McLane'], ['MakeUseOf'], ['Pulo'], ['Elephanta'], ['愛'], ['Bendon'], ['DPO'], ['OHjobs'], ['Lik'], ['naturopaths'], ['CategoryAppetizers'], ['M.A.T.'], ['broadened'], ['SAMI'], ['Praising'], ['chemometrics'], ['Doyles'], ['Hokianga'], ['Backpacker'], ['1,500.00'], ['calma'], ['D3300'], ['Craic'], ['VegNews'], ['rawness'], ['chemometrics'], ['penalty'], ['Cheerwine'], ['Neogen'], ['Bobi'], ['Offering'], ['Clubs'], ['McLane'], ['low-to-mid'], ['Sinema'], ['Introvert'], ['sweetie'], ['Cannone'], ['11-7'], ['Bataan'], ['BMI'], ['Mairi'], ['15.85'], ['Deion'], ['breadth'], ['Méridien'], ['Trump-fueled'], ['adoption'], ['Roxon'], ['Kassy'], ['Tasnim'], ['republicanism'], ['Babauta'], ['Offer'], ['republicanism'], ['narrowed'], ['Lazor'], ['applied.Find'], ['Yared'], ['Offensively'], ['Hands-On'], ['republicanism'], ['half-back'], ['frontrunner'], ['Eli'], ['8am-6pm'], ['Candra'], ['Lunch'], ['Dannell'], ['scolded'], ['AHPRA'], ['Mercy'], ['Tasnim'], ['2017Belgium'], ['USCS'], ['Horticulturist'], ['Bryggen'], ['PhoneWebOfficeVPN'], ['Liberi'], ['giveaway'], ['CHF'], ['SlovenščinaMeter'], ['Begich'], ['CHF'], ['1.9k'], ['38-41'], ['sweepstakes'], ['Candra'], ['plugin.Contributors'], ['eTrex'], ['Coos'], ['Quirk'], ['Jizzed'], ['Maaji'], ['within'], ['Rulli'], ['calma'], ['BreakfastPlats'], ['OLYMPUS'], ['YPor'], ['Verbose'], ['Bataan'], ['Hourly'], ['Horticulturist'], ['frontrunner'], ['WatchGuard'], ['viticulturist'], ['iCare'], ['Nuevo'], ['stumbled'], ['Ginn'], ['applied.Find'], ['FitnessFree'], ['DMACC'], ['breath-hold'], ['Bakeshop'], ['Maaji'], ['it.Learn'], ['McLane'], ['MoreYou'], ['attendees'], ['Horticulturist'], ['Rubenesque'], ['Monsivais'], ['Plantagenet'], ['BQ'], ['Dinan'], ['30-10'], ['Bogart'], ['embrace'], ['CareLifestyle'], ['Lead411'], ['aimed'], ['Co-director'], ['Buono'], ['SaleValuesRebates'], ['Maaji'], ['Ginger'], ['Brandan'], ['NNA'], ['Dea'], ['77S'], ['anti-illegal'], ['Natera'], ['tanginess'], ['Pando'], ['3m1'], ['Soupy'], ['Bioconductor'], ['Barkett'], ['Invoke'], ['Lexie'], ['Clausen'], ['Nippers'], ['Webtrends'], ['lineup'], ['123s'], ['midpoints'], ['PRISM'], ['DPReview'], ['Tasnim'], ['inlet'], ['Anam'], ['Karbon'], ['uncharted'], ['breathless'], ['ReachLocal'], ['Jang'], ['Cinta'], ['Newcomer'], ['viste'], ['Meagan'], ['Pulo'], ['Founders'], ['77S'], ['Bullies'], ['Micca'], ['xeriscaping'], ['Horticulturist'], ['Tasnim'], ['Hoppner'], ['partywear'], ['Coulomb'], ['Steinle'], ['FreeDigitalPhotos.net'], ['Penzo'], ['Graston'], ['ListIdeal'], ['Tasnim'], ['Tasnim'], ['Snooky'], ['Manger'], ['Jaynie'], ['enunciates'], ['Tasnim'], ['sustainabilitea'], ['bark'], ['Ceberano'], ['business-minded'], ['24-week'], ['breath-hold'], ['Extraordinary'], ['Tasnim'], ['coon'], ['DoctorsYahoo'], ['Megger'], ['Tasnim'], ['Tasnim'], ['coasteering'], ['Bernbach'], ['Outten'], ['Mums'], ['royalty'], ['strengths'], ['Sciortino'], ['Geaux'], ['Grads'], ['CareLifestyle'], ['Barcodes'], ['Yogurtland'], ['NEX'], ['frontrunner'], ['GSEA'], ['heart'], ['outdoors'], ['Tasnim'], ['Castroville'], ['Cão'], ['Jodee'], ['Expressly'], ['Smilin'], ['Salish'], ['Violators'], ['LSG'], ['Kingstown'], ['Grads'], ['Kally'], ['phylogenetics'], ['pounced'], ['smiled'], ['iconoclasts'], ['ocr'], ['Woofs'], ['scaredy'], ['Kari'], ['Buress'], ['pmSat'], ['bientot'], ['Paycom'], ['Pulau'], ['Pllc'], ['Currin'], ['2016POPULAR'], ['familiarized'], ['Drummoyne'], ['Morice'], ['bullet'], ['Brunch'], ['Sunsets'], ['Cigna'], ['non-cancerous'], ['Souvlaki'], ['1dB'], ['sass'], ['COOKIE'], ['slogan'], ['maman'], ['Jumpin'], ['2017Where'], ['destinationsRest'], ['AMMO'], ['Maaji'], ['11-7'], ['ListIdeal'], ['Abbott'], ['MST'], ['opposites'], ['Brien'], ['feistier'], ['Cuan'], ['GLUT4'], ['UsPhone'], ['Warid'], ['Kilis'], ['Manger'], ['OH'], ['Biscuits'], ['Wurtzbach'], ['Mobilink'], ['four-leaf'], ['Doy'], ['PMAmazing'], ['Snooky'], ['PetSitter.com'], ['Etelä-Wales'], ['7.87'], ['fierceness'], ['Trump-fueled'], ['Millett'], ['Laughing'], ['77S'], ['Portraiture'], ['prouder'], ['Broadsheet'], ['PM-8'], ['Endearing'], ['Kingaroy'], ['Horticulturist'], ['Yared'], ['Maaji'], ['dewdrop'], ['Picnics'], ['quicken'], ['Kriseman'], ['WIN-WIN'], ['Abbott'], ['ylw-pushpin1.3http'], ['widest'], ['kecap'], ['Flaunt'], ['Roka'], ['sportsnewsarena'], ['disabled.Protect'], ['Kapalua'], ['Violators'], ['squinted'], ['S-S'], ['Asmat'], ['Chatto'], ['unconditional'], ['playmaker'], ['Huckins'], ['broadened'], ['findingaids'], ['Worship'], ['Butuan'], ['Pix'], ['Marye'], ['ProLife'], ['TypeKey'], ['PMAmazing'], ['Zumbo'], ['Sí'], ['Lunch'], ['Hunx'], ['EditionYahoo'], ['Ache'], ['QUESTION'], ['HOLDIT'], ['Goude'], ['D400'], ['name-'], ['510'], ['frontrunner'], ['Goude'], ['Vinal'], ['Co-Parenting'], ['Gangas'], ['Goude'], ['SAMI'], ['A-M'], ['ylw-pushpin1.3http'], ['Late-Night'], ['Metropol'], ['Satele'], ['Deion'], ['quantified'], ['Supermodel'], ['Guava'], ['Bernbach'], ['CareLifestyle'], ['Goude'], ['Arriving'], ['Gabbiadini'], ['ReplyDeleteAnnie'], ['adventurous'], ['Jpegs'], ['D5300'], ['Umhlanga'], ['D400'], ['PMAmazing'], ['Ilha'], ['Kriseman'], ['Magdelene'], ['Verbose'], ['McAlexander'], ['POLK'], ['Goude'], ['Goude'], ['Bassike'], ['Larrikin'], ['Goude'], ['partakers'], ['FacebookView'], ['Len'], ['Offering'], ['Offensively'], ['Goude'], ['FLYFLV'], ['1705230'], ['abouth'], ['neither'], ['17-50mm'], ['Marigolds'], ['melasma'], ['carve'], ['88-92'], ['One-Stop'], ['Sevigny'], ['overviewing'], ['Beaucoup'], ['17-50mm'], ['PMAmazing'], ['Outten'], ['Shahi'], ['ambiguity'], ['familiarized'], ['Yared'], ['pomp'], ['Chocoholic'], ['Donauwörth'], ['Glam'], ['TOGAF'], ['ADT'], [\"'Rivera\"], ['Deli'], ['Len'], ['widest'], ['Merricks'], ['MCT'], ['AAFCO'], ['Thorell'], ['Rumpy'], ['17-50mm'], ['BillionGraves'], ['Bogart'], ['Hunx'], ['Cruises'], ['CategoryAppetizers'], ['idolaters'], ['co-starred'], ['Brulee'], ['Aways'], ['GOAL'], ['Burnt'], ['Dulin'], ['InstagramView'], ['Pre-Paid'], ['Graney'], ['Nafplio'], ['fields---Title'], ['ReplyDeleteRepliesLinda'], ['Falsely'], ['Neuroimaging'], ['gusting'], ['MDA'], ['IACP'], ['Steinle'], ['Vag'], ['aboral'], ['stalagmite'], ['1-855-932-4822'], ['sass'], ['Nuevo'], ['CCAI'], ['Luar'], ['viticulturist'], ['balked'], ['sportsnewsarena'], ['Trixi'], ['Illustrators'], ['Staithes'], ['Nutbush'], ['DiDomenico'], ['Opelousas'], ['Keithley'], ['coon'], ['Zambales'], ['Bataan'], ['Maaji'], ['Dunsborough'], ['2010-2019'], ['Bakassi'], ['equilateral'], ['Pee'], ['ReasonAccent'], ['universityLog'], ['20-week'], ['Monett'], ['ARIZ'], ['Raffle'], ['Jumpin'], ['P-Town'], ['Pots'], ['aground'], ['Flattery'], ['SB203580'], ['anti-surface'], ['Hertling'], ['Sitti'], ['Printmaking'], ['CategoryAppetizers'], ['Thee'], ['Walk-ins'], ['Kingaroy'], ['playmaker'], ['pitty'], ['volver'], ['TBA'], ['Xoxo'], ['tatts'], ['Estheticians'], ['toothless'], ['familiarized'], ['playmaker'], ['anti-surface'], ['CategoryAppetizers'], ['man-woman'], ['UsAll'], ['breath-taking'], ['anti-surface'], ['anti-surface'], ['bygone'], ['Corned'], ['Selfies'], ['Dea'], ['luck'], ['Offensively'], ['straddled'], ['Warmoth'], ['Cuppa'], ['Tuition'], ['Offensively'], ['X-Rite'], ['Unflavored'], ['Siam'], ['Plibersek'], ['VPC'], ['trade-marks'], ['Limelight'], ['Convictions'], ['gail'], ['Omega-3s'], ['roast'], ['ITEXPO'], ['cross-promote'], ['observed'], ['Sayang'], [\"'Acadie\"], ['creator-owned'], ['Iyke'], ['Hazelden'], ['Apayao'], ['Byes'], ['Durdle'], ['NDA'], ['WUKY'], ['Dara'], ['Hopalong'], ['anti-surface'], ['Colorburst'], ['Porcello'], ['self-starters'], ['forget'], ['ProMaster'], ['ATEN'], ['jawline'], ['Vivint'], ['Bettys'], ['Feinstein'], ['unnerving'], ['Jurai'], ['Gile'], ['abouth'], ['calmness'], ['CategoryAppetizers'], ['Boldly'], ['Shrove'], ['Decadal'], ['mastered'], ['elucidated'], ['Sevigny'], ['introspection'], ['Deli'], ['Crikey'], ['Pimples'], ['Moyen'], ['Sisa'], ['Boka'], ['billboards'], ['Sundown'], ['WBENC'], ['60px'], ['doTERRA'], ['KLEW'], ['Orana'], ['Mums'], ['ljubav'], ['Expungement'], ['Gotcha'], ['Pharmacist'], ['K9'], ['sunglassesWomen'], ['Yared'], ['Maryellen'], ['ITV3'], ['1,916'], ['Kally'], ['GCE'], ['Kinnaman'], ['S-S'], ['Gringa'], ['Pluronic'], ['Sli'], ['FCUK'], ['roomProperty'], ['ManagerRestaurant'], ['frontrunner'], ['Kaity'], ['Detours'], ['Arey'], ['77S'], ['0-for-3'], ['aquatint'], ['Dara'], ['Durdle'], ['κοινοποιήσετε'], ['FacebookView'], ['Maaji'], ['luck'], ['Lamby'], ['best-in-class'], ['Cozies'], ['Photogenic'], ['Bouley'], ['Yodle'], ['Dara'], ['Me-TV'], ['VanZant'], ['abouth'], ['Dropsy'], ['Dennings'], ['pounced'], ['Nuevo'], ['emergeLATEST'], ['magnification'], ['frontrunner'], ['noontime'], ['npr.org.'], ['Frederiksted'], ['smiled'], ['Fania'], ['Natives'], ['on-the-water'], ['shimmery'], ['Pey'], ['Phlebotomist'], ['chiseled'], ['Uson'], ['Selfies'], ['PRISM'], ['Steinle'], ['Glassdoor'], ['Hons'], ['Horticulturist'], ['studied'], ['Jueves'], ['champs'], ['Pisang'], ['Sevigny'], ['CategoryAppetizers'], ['smoothed'], ['Mums'], ['non-cancerous'], ['FLYFLV'], ['Akimbo'], ['IACP'], ['Micca'], ['Surprise'], ['pequeno'], ['frontrunner'], ['applicatons'], ['NIV'], ['CommonWealth'], ['Peek-A-Boo'], ['Sevigny'], ['ambiguity'], ['PRICED'], ['familiarizing'], ['Bummed'], ['windage'], ['NowAlready'], [\"'arcy\"], ['WnW'], ['Hanlan'], ['kgs'], ['AdultCompatibility'], ['familiar'], ['Claflin'], ['midpoints'], ['HANGUP'], ['Drummoyne'], ['CategoryAppetizers'], ['TVCs'], ['Authorized'], ['Pepsodent'], ['Raho'], ['viticulturist'], ['Kerrigan'], ['rafflecopter'], ['frontrunner'], ['12dB'], ['Choclette'], ['fiercely'], ['stocklistingshome'], ['KNTV'], ['Paihia'], ['Magnuson'], ['tropism'], ['quantified'], ['fame'], ['softer'], ['SBs'], ['rallys'], ['KUSA'], ['reflux'], ['frontrunner'], ['complected'], ['Siak'], ['CottageHinta'], ['Kila'], ['20dB'], ['Tablature'], ['usWe'], ['Internships'], ['Dinning'], ['2pac'], ['Introvert'], ['Mallette'], ['Mingle'], ['COTD'], ['syncretism'], ['partakers'], ['Chocoholic'], ['Chocoholic'], ['supercouple'], ['Time-Out'], ['SB203580'], ['Kally'], ['Punch-Drunk'], ['CategoryAppetizers'], ['labe'], ['CategoryAppetizers'], ['Squirts'], ['Soupy'], ['Lošinj'], ['Unterseeboot'], ['ELISA'], ['100.7'], ['McIlrath'], ['Colan'], ['Molyvos'], ['Uniques'], ['anti-surface'], ['Kara'], ['IPPY'], ['Buddah'], ['lowercase'], ['mofongo'], ['Glimpse'], ['vulgarity'], ['glassmaking'], ['LightStim'], ['Muy'], ['frontrunner'], ['viticulturist'], ['airbrushed'], ['ISV'], ['overlapped'], ['Eydie'], ['uppercase'], ['LC9'], ['Kybella'], ['MUBI'], ['ChristianSpiritualityResourcesBlogsColumnsReligion'], ['Artwalk'], ['Chocoholic'], ['Oglio'], ['Freya'], ['Denison'], ['Yared'], ['viticulturist'], ['Sápmi'], ['Lamontagne'], ['Chins'], ['bittering'], ['CategoryAppetizers'], ['Pasty'], ['RANKL'], ['Charlies'], ['Falz'], ['Heckler'], ['CategoryAppetizers'], ['Cuppa'], ['BECCA'], ['Deanna'], ['Aways'], ['decentralization'], ['Meeko'], ['Nanny'], ['Shangri'], ['Pras'], ['Nocenti'], ['10.00pm'], ['Vivitrol'], ['PayPerPost'], ['Beckey'], ['convienence'], ['Lošinj'], ['SeaChange'], ['up-sell'], ['Fralin'], ['Founders'], ['Dare'], ['vwr.com.'], ['RoRo'], ['grit'], ['Smyers'], ['pounced'], ['2017Post'], ['MELO'], ['extol'], ['45-49'], ['Tonnage'], ['Newcomer'], ['Arundell'], ['Irresistibly'], ['50-200'], ['Wenche'], ['minutes'], ['44This'], ['mI'], ['pittie'], ['Agates'], ['interpretative'], ['Panthéon'], ['Wiggs'], ['greyhounds'], ['Caldbeck'], ['Halfmoon'], ['friendlier'], ['viticulturist'], ['Linny'], ['oiliness'], ['CategoryAppetizers'], ['backlighting'], ['fainthearted'], ['PEMRA'], ['Ganesan'], ['Charlies'], ['bog'], ['IACP'], ['Jamai'], ['Lottery'], ['alones'], ['COOH'], ['DeJohnette'], ['mid-tone'], ['offish'], ['Officially'], ['Kx'], ['Karon'], ['Taqueria'], ['Steidl'], ['Elephanta'], ['frontrunner'], ['Me-TV'], ['Westbrook'], ['PeekYou'], ['reporters'], ['Kims'], ['Deadstar'], ['repeller'], ['domaine'], ['frontrunner'], ['amor'], ['100.The'], ['GuidelinesPrivacy'], ['frontrunner'], ['Linkup'], ['Graney'], ['paws'], ['Macanese'], ['K9s'], ['CategoryAppetizers'], ['blackberry'], ['BarkBox'], ['FUNERAL'], ['discolorations'], ['procoagulant'], ['Ruen'], ['industry-wide'], ['JSM'], ['Geospatial'], ['frontrunner'], ['Tannenbaum'], ['Yerba'], ['1705230'], ['glowed'], ['lard'], ['Sweepstake'], ['Snee'], ['Petoskey'], ['azulejos'], ['Officina'], ['Tiwa'], ['Meant'], ['Polisario'], ['RENEWED'], ['multi-published'], ['tripods'], ['Deadstar'], ['Keithley'], ['RED'], ['MUF'], ['sweetie'], ['Cabanatuan'], ['Literary'], ['boasted'], ['Pangs'], ['Sápmi'], ['maritimes'], ['Restoran'], ['SPICY'], ['OptionsDigital'], ['Dingmans'], ['Arakan'], ['Wieden'], ['Maaji'], ['carfentanil'], ['skeeters'], ['broaden'], ['studySearch'], ['torr'], ['EXPOSURE'], ['frontrunner'], ['Clients'], ['Tipis'], ['pukul'], ['Chock'], ['MoCCA'], ['mid-coast'], ['AAHA'], ['DenizDevOps'], ['USCS'], ['Percé'], ['Samadhi'], ['Felisha'], ['Hexane'], ['Ballycotton'], ['Adore'], ['Roissy'], ['Dumba'], ['Steinle'], ['Majorette'], ['USAP'], ['Bataan'], ['ruggedness'], ['frontrunner'], ['Daddies'], ['Sápmi'], ['Mutrie'], ['fostered'], ['2013Exhibit'], ['Herrod'], ['SeaChange'], ['Miller-Heidke'], ['Acho'], ['publisher'], ['disrespect'], ['Sogno'], ['Internships'], ['Niah'], ['undescribable'], ['frontrunner'], ['on-the-water'], ['frontrunner'], ['addy'], ['Hadhramaut'], ['Larrikin'], ['frontrunner'], ['Ivybridge'], ['Claridges'], ['Me-TV'], ['abouth'], ['doomed'], ['Alphonse'], ['shimmering'], ['bienvenue'], ['scorn'], ['Bangka'], ['Pocari'], ['NPN'], ['NAFLD'], ['2,564'], ['AMER'], ['Work-Life'], ['frontrunner'], ['Pataky'], ['Huggs'], ['USP'], ['well-received'], ['Ledge'], ['NRA'], ['Leatherwood'], ['phial'], ['1,450,000'], ['Pistol'], ['photojournalism'], ['cbet'], ['MiGs'], ['frontrunner'], ['patera'], ['ugliness'], ['BARCO'], ['Doggone'], ['dry.'], ['Ireton'], ['Arundell'], ['MSK'], ['DPO'], ['Zumbo'], ['Treen'], ['Siddharta'], ['Mamas'], ['ANYWHERE'], ['ReadTexas'], ['10am-3pm'], ['microclimate'], ['Windswept'], ['Revillame'], ['Phlebotomist'], ['ddr2'], ['Mwah'], ['parable'], ['immunoassays'], ['aspired'], ['Nancie'], ['prude'], ['chowhound'], ['besoin'], ['Ceol'], ['Infringement'], ['AdultCompatibility'], ['gastronomy'], ['Raynsford'], ['embraced'], ['Alef'], ['Barren'], ['34B'], ['lawfirm'], ['ONVIF'], ['BQ'], ['Craic'], ['Hunx'], ['microalbuminuria'], ['metabolisms'], ['Cinematographer'], ['SB203580'], ['Bilger'], ['Jamai'], ['COLUMNS'], ['Steinle'], ['Jodee'], ['CategoryAppetizers'], ['emblazoned'], ['Luckenbach'], ['appending'], ['cleary'], ['Gelatos'], ['doorjamb'], ['you.Take'], ['Jumpin'], ['sung'], ['Dickason'], ['frontrunner'], ['Soave'], ['Gunsmoke'], ['Kahi'], ['frontrunner'], ['Cà'], ['manhunt'], ['Rubies'], [\"'hôtesCapacité\"], ['frontrunner'], ['Hunx'], ['Micca'], ['Preckwinkle'], ['gaiwan'], ['RootsTech'], ['Immeasurable'], ['Bernbach'], ['App'], ['Newcomer'], ['aspired'], ['AltLd'], ['Relaxation'], ['blaster'], ['Arakan'], ['scornful'], ['CategoryAppetizers'], ['1705230'], ['CFD'], ['abrogated'], ['Larranaga'], ['decentralization'], ['Glaciology'], ['Slik'], ['examined'], ['Muruga'], ['aspired'], ['Keithley'], ['windage'], ['Francophile'], ['9X'], ['iconoclasts'], ['Lanesboro'], ['obsessiveness'], ['Barkett'], ['Outside'], ['CategoryAppetizers'], ['Surprise'], ['dash'], ['ADEX'], ['Rochford'], ['Boscov'], ['SDMA'], ['ceili'], ['Sharia'], ['sandbar'], ['Priceless'], ['mid-coast'], ['better.We'], ['4,850'], ['SAG-AFTRA'], ['STNA'], ['Stonnington'], ['PowerShell'], ['Adventuress'], ['Doulos'], ['sheerly'], ['anti-retaliation'], ['focals'], ['Posta'], ['Skolnik'], ['Boursin'], ['Biocare'], ['Tuesday-Sunday'], ['CHFI'], ['Lamontagne'], ['Londra'], ['Curvy'], ['Ranna'], ['UsWork'], ['Problogger'], ['inebriation'], ['Ink-Jet'], ['Fowlers'], ['Abraxane'], ['quick-draw'], [\"'Auberge\"], ['lauched'], ['frontrunner'], ['Rotolo'], ['AdultCompatibility'], ['Vidi'], ['Chewa'], ['Goans'], ['meAll'], ['SysWOW64'], ['GAAP'], ['Ironweed'], ['frontrunner'], ['Madhubani'], ['Doesn'], ['Cokin'], ['Riso'], ['borderlines'], ['Agness'], ['though.You'], ['businesswire.com'], ['caul'], ['Seafolly'], ['Coloane'], ['luk'], ['Barkers'], ['B1G1'], ['Matriculation'], ['Till'], ['ARMANI'], ['17-50mm'], ['partnerships'], ['Stubborn'], ['Webtrends'], ['Spit'], ['Tiwa'], ['Pitbulls'], ['Micca'], ['Giffords'], ['forget'], ['Starlit'], ['Walk-ins'], ['Jabo'], ['frontrunner'], ['dianne'], ['Sunsets'], ['0755'], ['Shalvis'], ['Penpals'], ['Jax'], ['phylogenetics'], ['Haymes'], ['Pitty'], ['Charlies'], ['aspired'], ['Luncheon'], ['Lokal'], ['Tuesday-Thursday'], ['Marro'], ['taxidermist'], ['bigs'], ['EYEWEAR'], ['Corita'], ['Dine'], ['aground'], ['CodesInkredible4'], ['Industry-Leading'], ['BRIX'], ['Tava'], ['iconoclasts'], ['IACP'], ['aspired'], ['Buri'], ['Uniques'], ['per-game'], ['Taffy'], ['Crafternoon'], ['admire'], ['Hottero'], ['namesakes'], ['Starlit'], ['Zahle'], ['JOLLY'], ['Natives'], ['Dea'], ['blarney'], ['Larratt'], ['pre-established'], ['Weren'], ['Talise'], ['frontrunner'], ['Verd'], ['spurts'], ['Inaccessible'], ['Paczkowski'], ['Rozay'], ['detailsall'], ['Revlon'], ['SFDC'], ['Scalia'], ['Chins'], ['MathematicBusiness'], ['Ganda'], ['Dare'], ['langs'], ['IKON'], ['Duni'], ['NPN'], ['DHEC'], ['demeaning'], ['Hyperlapse'], ['Ellenborough'], ['Jail'], ['Arriaga'], ['Rifka'], ['observed'], ['vurdering'], ['sass'], ['aspired'], ['Romania.svg'], ['Adrenaline'], ['BHA'], ['en-us'], ['Kookie'], ['Maghera'], ['0.100'], ['Mums'], ['opened'], ['Ballston'], ['Criteo'], ['Comatmebro'], ['Captivated'], ['bewitch'], ['Francophiles'], ['calcein'], ['Penpals'], ['allopathic'], ['sadden'], ['smoking'], ['rte'], ['Bechet'], ['Verve'], ['aspired'], ['Silverheels'], ['Pre-Kindergarten'], ['Seafolly'], ['baying'], ['Vx'], ['sunbursts'], ['ISBNs'], ['AppsSubscribeAdvertise'], ['chiropractors'], ['Killjoys'], ['COMPETES'], ['kafir'], ['Walk-ins'], ['alone.It'], ['Shafiroff'], ['Pekar'], ['Dramatically'], ['VNA'], ['kerr'], ['CodesInkredible4'], ['Pontianak'], ['Fine'], ['Aways'], ['M58'], ['Phee'], ['28-33'], ['ShowsCountdown'], ['Intronis'], ['Anak'], ['2016Just'], ['Positivity'], ['gunwale'], ['Stilettos'], ['OH'], ['Ma-'], ['Tasteless'], ['Zaman'], ['Insha'], ['OUI'], ['italics'], ['Razors'], ['Colchagua'], ['VADAKAYIL'], ['Calwell'], ['pedimented'], ['Chadwick'], ['vied'], ['Micca'], ['in-licensing'], ['broadened'], ['first-in-class'], ['Maaji'], ['aggressiveness'], ['uplight'], ['HQN'], ['applicatons'], ['Dennings'], ['schoolwide'], ['Chanté'], ['Digoxin'], ['Joh'], ['kingdom'], ['never'], ['blazed'], ['Uzair'], ['effigy'], ['tasty.'], ['Ambos'], ['self-absorption'], ['MondayTuesdayWednesdayThursdayFridaySaturdaySundayYou'], ['Congonhas'], ['Laboy'], ['unfocused'], ['Trilingual'], ['it.Have'], ['ushering'], ['givaway'], ['Adora'], ['IACP'], ['3ch'], ['Broaden'], ['SeaDek'], ['Evanger'], ['Joking'], ['aspired'], ['2.5D'], ['PBS'], ['BLACKBERRY'], ['dripped'], ['NAMES'], ['examined'], ['aspired'], ['WOSU'], ['Marketo'], ['CD105'], ['PASSIONATE'], ['observed'], ['CategoryAppetizers'], ['Coadministration'], ['boggles'], ['idiosyncrasies'], ['gamut'], ['Mahalia'], ['Mali-T600'], ['Relaxin'], ['77S'], ['Braai'], ['LC9'], ['CountyContestsContent'], ['Salish'], ['vallée'], ['Ancora'], ['enticement'], ['Loca'], ['Rolfes'], ['Argosy'], ['Warmoth'], ['1024px'], ['eugenol'], ['Vidi'], ['Charco'], ['Ré'], ['Salty'], ['800km'], ['as-is'], ['JMHO'], ['GROOMING'], ['107.4'], ['nanomolar'], ['Lead411'], ['Gaelyn'], ['9995'], ['Grads'], ['Siak'], ['Trollfest'], ['2549'], ['Baptisms'], ['audibles'], ['Krieghoff'], ['MUTUAL'], ['enroll'], ['Saje'], ['bronzers'], ['Mopsy'], ['3ch'], ['PLAT'], ['Valued'], ['Frankly'], ['Vegetarian'], ['Graney'], ['Cowens'], ['Herkimer'], [\"'America\"], ['IACP'], ['Slainte'], ['smiled'], ['four-leaf'], ['Top-rated'], ['Maaji'], ['anti-marriage'], ['iFamCare'], ['2760'], ['Boursin'], ['Specsavers'], ['labe'], ['Paediatrician'], ['500-year-old'], ['anti-pollution'], ['grinned'], ['JazzTimes'], ['unfurled'], ['alon'], ['Buzzy'], ['LOBSTER'], ['3637'], ['sunbursts'], ['2,657'], ['Fuso'], ['faintly'], ['abouth'], ['Catchy'], ['CategoryAppetizers'], ['Tzatziki'], ['6p.m.'], ['R70'], ['DsouzaCategories'], ['Me-TV'], ['observed'], ['Casemate'], ['Inkwell'], ['Essence'], ['Cuppa'], ['10457'], ['3Rs'], ['GuidelinesPrivacy'], ['35lbs'], ['heritages'], ['CategoryAppetizers'], ['RESPECT'], ['saty'], ['Bogart'], ['Chalo'], ['Volubilis'], ['white-washed'], ['aventurine'], ['Westergren'], ['Nathalia'], ['Tramonto'], ['E-liquid'], ['Expecting'], ['mapWe'], ['Dosha'], ['VPC'], ['2015-17'], ['3ch'], ['10012'], ['pan-Asian'], ['JOLLY'], ['30sec'], ['grimaced'], ['3ch'], ['Craic'], ['niche'], ['BarkBox'], ['Haslem'], ['11am-3pm'], ['McLaury'], ['Authentically'], ['Sprigg'], ['45lbs'], ['Exterminating'], ['3ch'], ['Hagan'], ['BOLO'], ['M.Ed.'], ['Doolin'], ['capitaine'], ['Tweet'], ['spicier'], ['PLNрубSGD'], ['TwitterWhat'], ['Chrissi'], ['Dennings'], ['ADEX'], ['Molyvos'], ['Griezmann'], ['F.D.A.'], ['fearlessness'], ['Exhibitor'], ['handprints'], ['5.05This'], ['Frizell'], ['Calxeda'], ['5.0Easy'], ['WGBH'], ['venerates'], ['inconspicuously'], ['parasitics'], ['250-350'], ['grimaced'], ['CategoryAppetizers'], ['DiNovo'], ['Spicey'], ['talisman'], ['Sanganer'], ['3ch'], ['WPPI'], [\"'hôtesCapacité\"], ['Farol'], ['Tannenbaum'], ['LMNA'], ['Hario'], ['Uncork'], ['iFamCare'], ['dialect'], ['dialect'], ['Hautelook'], ['backstamp'], ['X-Rite'], ['3ch'], ['Moana'], ['assays'], ['co-branding'], ['dismayed'], ['BookSurfCamps'], ['Richardsons'], ['Cowart'], ['Darlinghurst'], ['IACP'], ['Travail'], ['Rotel'], ['LATA'], ['Cuca'], ['multimodal'], ['Kenneally'], ['IPAs'], ['AIW'], ['00ZCentral'], ['Intersections'], ['Sli'], ['channel'], ['spectrometers'], ['TermsWTF'], ['3ch'], ['rockier'], ['bronzes'], ['LUNs'], ['Maaji'], ['luk'], ['MassChallenge'], ['chancers'], ['Chimo'], ['in-licensing'], ['Britania'], ['Allmand'], ['CPMs'], ['OPTIMA'], ['powerplays'], ['niente'], ['Certifications'], ['Moosa'], ['Rubenesque'], ['1333MHz'], ['MoreYou'], ['Liveright'], ['SPCA'], ['vain'], ['spirits'], ['LVH'], ['iFamCare'], ['venomous'], ['532nm'], ['immunoassays'], ['3-digit'], ['275,000'], ['Moonshiners'], ['wrath'], ['CategoryAppetizers'], ['fascinated'], ['live.com.'], ['loue'], [\"'hôtesCapacité\"], ['Charpentier'], ['Methodology'], ['AAFCO'], ['DEEDS'], ['more.At'], ['seized'], ['coastlands'], ['timepoints'], ['Redfish'], ['distain'], ['Modica'], ['Nudity'], ['tge'], ['Pardy'], ['sunbursts'], ['carfentanil'], ['Zatarain'], ['Self-Evaluation'], ['endorsements'], ['Strait'], ['0.375'], ['bonjour'], ['Thorofare'], ['Loisirs'], ['NSString'], ['Natchez'], ['Kahanamoku'], ['Refreshment'], ['Ais'], ['Vindictive'], ['sindoor'], ['Erskineville'], ['Diu'], ['-South'], ['Xsolla'], ['Hirst'], ['footlights'], ['Kidding'], ['Sally-Ann'], ['point-like'], ['2017RT'], ['CPMs'], ['zaman'], ['HB'], ['3ch'], ['circulations'], ['Hohenlohe'], ['OCLC'], ['Satguru'], ['Dea'], ['einfach'], ['Zahle'], ['Losinj'], ['Osheaga'], ['2.375'], ['amable'], ['NRJ'], ['Absorbance'], ['Larrañaga'], ['Calusa'], ['VAComments'], ['McAlexander'], ['Greenup'], ['Cheeta'], ['Rochford'], ['Maaji'], ['Thalassotherapy'], ['Romantic'], ['symbolising'], ['Ongaku'], ['Myleene'], ['greenish-blue'], ['Abgar'], ['Edifier'], ['Blasphemy'], ['pouted'], ['best-in-class'], ['Wildwoods'], ['Furber'], ['Haight'], ['ABCS'], ['Wari'], ['outmanoeuvred'], ['3ch'], ['PALO'], ['Maaji'], ['tge'], ['HomeMattersParty'], ['Bayernliga'], ['Virgin'], ['mounts'], ['moreSimilar'], ['re-installed'], ['Collars'], ['Lygon'], ['Portugese'], ['SRT'], ['Newk'], ['life-partner'], ['pastilles'], ['3ch'], ['Stilettos'], ['passeggiata'], ['Kher'], ['unyielding'], ['Kait'], ['insurance-related'], ['nanomolar'], ['co-sponsors'], ['Home'], ['Sibillini'], ['Phlebotomist'], ['Pisang'], ['Geikie'], ['respond'], ['pitbull'], ['Ceberano'], ['abouth'], ['Sli'], ['MarketRiders'], ['Larranaga'], ['Addict'], ['Hinchinbrook'], ['Yared'], ['Tuition'], ['kitchen-sink'], ['SAA'], ['Mums'], ['whoremongers'], ['AustraliaNew'], ['Rifa'], ['Maaji'], ['Fiume'], ['people-centric'], ['Cheez'], ['3ch'], ['hugged'], ['Co-starring'], ['HighestHighest'], ['Cheerwine'], ['Sicily'], ['Hapsburgs'], ['Biscuits'], ['JavaRanch'], ['6pts'], ['horizontals'], ['sunbursts'], ['Icmeler'], ['York1'], ['Jamo'], ['PagesSM'], ['touché'], ['Recognizes'], ['CategoryAppetizers'], ['Dingmans'], ['TermsWTF'], ['Better'], ['anywhere'], ['Receptionist'], ['5mL'], ['Currin'], ['3ch'], ['Plaice'], ['SAAM'], ['30sec'], ['GOTD'], ['Sharpie'], ['Glico'], ['yours.You'], ['Nagila'], ['Mums'], ['Triumphant'], ['friendlier'], ['Lamanai'], ['Brandilyn'], ['multiplication'], ['Matane'], ['aol.com.'], ['Losinj'], ['sunbursts'], ['6-Speed'], ['blog.3.'], ['waterproofs'], ['teamed-up'], ['Bollards'], ['kway'], ['Bona'], ['K9s'], ['Tried'], ['Soupy'], ['flush-mounted'], ['Through'], ['Rethymnon'], ['CategoryAppetizers'], ['Lošinj'], ['Harrisburg'], ['retests'], ['Thorell'], ['mispronouncing'], ['pmYou'], ['guile'], ['SOx'], ['RAPP'], ['CategoryAppetizers'], ['playwriting'], ['Goldens'], ['oposite'], ['Mebyon'], ['Satori'], ['Foothold'], ['uplight'], ['Paperbacks'], ['CategoryAppetizers'], ['DealsRestaurant'], ['Taqueria'], ['PaperbackTitle'], ['3ch'], ['Pocasset'], ['9100'], ['spread'], ['Bouley'], ['SPONSORSHIP'], ['Vinum'], ['supersedes'], ['Date'], ['Chins'], ['Kally'], ['touchwiz'], ['UsWork'], ['telemarketing'], ['Harpring'], ['MAVERICK'], ['ABLEAMMO.COM'], ['PROVE'], ['Actifio'], ['Tesuque'], ['Authorised'], ['Havasu'], ['6x9'], ['Heyjude'], ['unpopulated'], ['Yared'], ['microcirculation'], ['ReplyDeleteRepliesKatie'], ['observed'], ['judgemental'], ['silversmiths'], ['10012'], ['Jelly'], ['pawprint'], ['Dedes'], ['underexposed'], ['lence'], ['Nytorv'], ['Clarity'], ['K-Love'], ['SOLD'], ['Glico'], ['dsnylnd4me'], ['marked'], ['Coolin'], ['Wikoff'], ['two-burner'], ['Arktos'], ['LATA'], ['unsearchable'], ['Dennings'], ['Cued'], ['Wholey'], ['51200'], ['0o'], ['CD63'], ['SKY'], ['NTO'], ['Brading'], ['Subglacial'], ['Edition'], ['widest'], ['Famille'], ['stippling'], ['Elephanta'], ['Charpy'], ['Buono'], ['ArchivesHelpSite'], ['Sandara'], ['ria'], ['SPICY'], ['lege'], ['Keithley'], ['Mingle'], ['Sixpoint'], ['Hodgman'], ['Smilin'], ['moneyLearn'], ['PlayerUnknown'], ['glacier'], ['Copperas'], ['harshness'], ['Coteau'], ['Sardi'], ['CategoryAppetizers'], ['Sip'], ['business-minded'], ['Biery'], ['Tehreek'], ['EDT2017-05-23'], ['Enchong'], ['Monte'], ['McNett'], ['PerkinElmer'], ['CategoryAppetizers'], ['Arambol'], ['halftones'], ['Bantam'], ['solidifying'], ['EnglandG.1'], ['Shivaya'], ['Malphite'], ['Hunts'], ['ljubav'], ['Tamela'], ['stippling'], ['CategoryAppetizers'], ['Barnstable'], ['Jodee'], ['Trekkers'], ['Buon'], ['Cesme'], ['complaintsFind'], ['people.That'], ['SOLD'], ['onlooker'], ['Roka'], ['Sasak'], ['Unsaid'], ['Nyhavn'], ['boundries'], ['squinted'], ['you.Read'], ['sunbursts'], ['Cowards'], ['Deltaville'], ['Publican'], ['EYES'], ['reflashed'], ['Comhaltas'], ['Jini'], ['orer'], ['curios'], ['Me-TV'], ['badlands'], ['worlwide'], ['Kos'], ['Conty'], ['SMTnet'], ['staters'], ['Dreamforce'], [\"'hôtesCapacité\"], ['Liefde'], ['SMARTnet'], ['decentralization'], ['Pitty'], ['lithos'], ['Illustrating'], [\"'n'B\"], ['Cascia'], ['Smeared'], ['use-by'], ['TUITION'], ['humblest'], ['pay-per-call'], ['CD63'], ['Armpits'], ['tribes'], ['25ml'], ['irreverence'], ['WAT'], ['weepers'], ['Bande'], ['Economía'], ['1,972'], ['Ilha'], ['POLK'], ['Kalydeco'], ['endearment'], ['TSCShops.com'], ['Majha'], ['48-72'], ['etching'], ['lovelier'], ['.Never'], ['Pancho'], [\"'Arte\"], ['Qubit'], ['Granta'], ['Remick'], ['LaGuerta'], ['McCann'], ['pagead'], ['Kamerun'], ['SeaChange'], ['VAST'], ['LifestylePolitical'], ['rushmore'], ['espero'], ['heaven'], ['EBSCO'], ['Smoak'], ['Zuzu'], ['CategoryAppetizers'], ['dialect'], ['TVCs'], ['millimolar'], ['Grief'], ['misprint'], ['alabaster'], ['-Dan'], ['GateHouse'], ['cracklings'], ['HEFFNER'], ['CodesEden4Hampers6'], ['baggages'], ['Agencies'], ['Manuka'], ['Sikander'], ['Nancie'], ['walleyes'], ['125-150'], ['Enlighten'], ['Son'], ['Gen2'], ['smiled'], ['FacebookView'], ['searchAll'], ['Headquartered'], ['Roseberry'], ['Rano'], ['glare'], ['disbeliever'], ['inherit'], ['trusteth'], ['westernmost'], ['price-clipped'], ['SaleBook'], ['Postgraduates'], ['Gastown'], ['Chriss'], ['5speed'], ['Chock'], ['Raffle'], ['Non-Profits'], ['Witherell'], ['Buddah'], ['Nicki'], ['CategoryAppetizers'], ['Taronga'], ['Mums'], ['Kait'], ['roche'], ['Kohlhepp'], ['non-administrative'], ['DetailsShareDownloadFlagDescription'], ['McAlexander'], ['lence'], ['Boo'], ['Infringement'], ['stippling'], ['Petty'], ['Ha-Ha'], ['Pocasset'], ['regnal'], ['moss-covered'], ['BYOB'], ['CartAdd'], ['Me-TV'], ['Randox'], ['two-burner'], ['Kava'], ['Offering'], ['fee'], ['Pix'], ['Ogaden'], ['Maaji'], ['11am-3pm'], ['Coolin'], ['Grubhub'], ['Pitbulls'], ['Sunfoil'], ['PokéCommunity'], ['Karno'], ['Offerings'], ['970'], ['Necks'], ['Housley'], ['Wesson'], ['Syrena'], ['Get-Together'], ['emblazoned'], ['Jagger'], ['2,099'], ['Sin'], ['.Thank'], ['7011'], ['Opelousas'], ['Offerings'], ['PCAT'], ['range1.5'], ['Hunx'], ['SCAMMERS'], ['Sardi'], ['MapMastheadCondé'], ['trademarks'], ['Albergo'], ['visable'], ['IACP'], ['Acasta'], ['Salty'], ['Cellophane'], ['Logar'], ['Keithley'], ['Shook'], ['Women-Owned'], ['100dB'], ['TACT'], ['Yoli'], ['Contently'], ['CodesEden4Hampers6'], ['offended'], ['birthmarks'], ['Half-Day'], ['SeaChange'], ['ama'], ['Sauces'], ['Essence'], ['CategoryAppetizers'], ['paddling'], ['SeaChange'], ['FSc'], ['you.Whatever'], ['JavaRanch'], ['ekta'], ['Jamo'], ['untouchables'], ['RobinsonRyan'], ['Jails'], ['Coleridge-Taylor'], ['AMKaren'], ['Radiography'], ['Apse'], ['2013Beautiful'], ['Vidi'], ['DogsNow'], ['Sukabumi'], ['non-commissionable'], ['RAIN'], ['2-tailed'], ['GRAMMY'], ['ONYX'], ['DishNET'], ['Uluru'], ['DFP'], ['Intensives'], ['focals'], ['McColgan'], ['Sbisa'], ['Riopelle'], ['Fayaz'], ['diffucult'], ['Declare'], ['Mwah'], ['map1'], ['Lawford'], ['ransomed'], ['Zandalari'], ['Matlacha'], ['Esplanade'], ['Cheves'], ['ensnares'], ['Indiamen'], ['Networx'], ['Lampanelli'], ['boof'], ['hERG'], ['head-hunting'], ['AOpen'], ['brigand'], ['Nanci'], ['5In'], ['X79'], ['Losinj'], ['reflections'], ['blemishes'], ['stand-offish'], ['hybridity'], ['Lyran'], ['Mudpie'], ['Jeraphine'], ['FULLEST'], ['disparagement'], ['Swimwear'], ['Deirdra'], ['Spyderco'], ['Bolles'], ['Fellows'], ['533MHz'], ['Grief'], ['BOLO'], ['KOBO'], ['time-slot'], ['Trademark'], ['Sokak'], ['Fide'], ['Grads'], ['Jadeite'], ['Jericoacoara'], ['TDCI'], ['CategoryAppetizers'], ['permissable'], ['live.com.'], ['Harta'], ['orders.Warranty'], ['YYYY'], ['run-rate'], ['palate'], ['isola'], ['Chasseur'], ['thest'], ['quitters'], ['unprofessional'], ['reticle'], ['tenet'], ['Dads'], ['Enema'], ['Jeaniene'], ['poked'], ['Represents'], ['typographical'], ['Algonquin'], ['51200'], ['Charger'], ['Smeared'], ['Masterchef'], ['Remote'], ['Diffa'], ['calm'], ['infoClose'], ['smoking'], ['Miramichi'], ['EDTOntario'], ['noontime'], ['Internships'], ['Nicknames'], ['Exploit'], ['Graney'], ['broaden'], ['chemiluminescent'], ['Prosch'], ['Mojos'], ['unmistaken'], ['Oman'], ['Nisr'], ['Elenore'], ['attractant'], ['Jeni'], ['multimeter'], ['Beverage'], ['unmapped'], ['0.225'], ['MORBID'], ['offended'], ['progs'], ['Vidi'], ['Sportsmans'], ['Coons'], ['brutalist'], ['ALOHA'], ['FindRealJob.in'], ['sparred'], ['CategoryAppetizers'], ['GuidelinesPrivacy'], ['Storage24'], ['Taj'], ['AppleOne'], ['Watercolors'], ['Sportsman'], ['Lô'], ['Cinque'], ['nameplates'], ['5.04.7'], ['amIs'], ['Kally'], ['Vassiliou'], ['straddled'], ['non-residents'], ['aspic'], ['Jazmin'], ['Phila'], ['intermarrying'], ['Sonnier'], ['3db'], ['Killip'], ['Chewy.com'], ['Grads'], ['malkin'], ['MANDATORY'], ['Nescafe'], ['Molucca'], ['Editora'], ['sunday'], ['Thalia'], ['Apuan'], ['Arizal'], ['Diraja'], ['Hatched'], ['NetDimensions'], ['FashionMiranda'], ['Bettys'], ['shouted'], ['Skyhorse'], ['VID'], ['marrige'], ['EXPOSURE'], ['tonks'], ['halloumi'], ['2-tailed'], ['NATIVE'], ['Duas'], ['Sportsman'], ['Unsurpassed'], ['blazed'], ['Glad'], ['off-putting'], ['1yr'], ['delaPlex'], ['ignited'], ['Boatshed'], ['Doon'], ['proactive'], ['Graney'], ['invito'], ['StateImpact'], ['basicity'], ['DRA'], ['Hyatt'], ['Secchi'], ['POEM'], ['Neyo'], ['Farrugia'], ['Humility'], ['seatings'], ['Covet'], ['Serif'], ['Starsky'], ['Pastor'], ['translucence'], ['Smokes'], ['goodwill'], ['D5300'], ['Wamba'], ['EDT2017-05-28'], ['klipsch'], ['Robbi'], ['carnelian'], ['Vecchia'], ['horseAdvertise'], ['Arakan'], ['CategoryAppetizers'], ['Patra'], ['Openers'], ['Lyndy'], ['Aways'], ['blackstrap'], ['Punda'], ['Booking.com.'], ['overprinted'], ['ruggedly'], ['Dancin'], ['poofed'], ['Chele'], ['inVentiv'], ['DERMAdoctor'], ['Lunch'], ['Licencing'], ['36D'], ['flagstone'], ['confrontational'], ['Burdi'], ['Tea'], ['StormTracker'], ['destinationsRest'], ['Brasso'], ['Smo'], ['BFN'], ['S-S'], ['Roxy'], ['Arakan'], ['Penwith'], ['Slay'], ['HospitalSt'], ['isl'], ['Jamo'], ['SR-71'], ['Cokin'], ['pets'], ['Forgiven'], ['Norheim'], ['Hashtag'], ['FairPlay'], ['Mocking'], ['glassmaking'], ['two-term'], ['COMEDY'], ['STNA'], ['cheekbones'], ['Biana'], ['Orford'], ['Hunx'], ['Seubert'], ['throughI'], ['Bront'], ['Sammi'], ['Heckler'], ['Snooky'], ['Barracudas'], ['CategoryAppetizers'], ['irremediably'], ['Gesso'], ['faceoffs'], ['Vado'], ['Aquent'], ['Kilham'], ['focal'], ['Ballsbridge'], ['repel'], ['isencrypted'], ['ROHS'], ['BRIX'], ['Hots'], ['bfg'], ['Kospi'], ['dine-in'], ['Muswell'], ['39-0'], ['SafetyHousingOverall'], ['discoloring'], ['pageants'], ['Bellegarde'], ['SORRY'], ['Emulsifiers'], ['VWR'], ['Tedy'], ['discoloured'], ['cross-hatching'], ['Photoplay'], ['2-tailed'], ['fearlessness'], ['XO'], ['springfield'], ['Tate'], ['live-music'], ['opposites'], ['LOBSTER'], ['judgemental'], ['Blasket'], ['altered'], ['business-minded'], ['unchartered'], ['Fat'], ['Terrazza'], ['Alexx'], ['Hary'], ['awayMovies'], ['OneRepublic'], ['paps'], ['grit'], ['Jamo'], ['fiercely'], ['Cioppino'], ['Gibraltarians'], ['Ancora'], ['Rocklands'], ['24mg'], ['Nutraceutical'], ['Wisemans'], ['signage'], ['lippy'], ['Fiume'], ['brightness'], ['Müzik'], ['sunburns'], ['Untamed'], ['Preflop'], ['894646'], ['meravigliosa'], ['etch'], ['Ubatuba'], ['3ch'], ['McWherter'], ['shallows'], ['Tactive'], ['noticible'], ['lence'], ['Oratio'], ['commentLoad'], ['cheminformatics'], ['No-Kill'], ['Greenslade'], ['JPs'], ['Puppy'], ['reigned'], ['diffusion'], ['Stanleys'], ['islets'], ['well-watered'], ['mout'], ['Sugaring'], ['freckles'], ['Sammi'], ['Wurtzbach'], ['Uncorked'], ['IACP'], ['Tutus'], ['IP3'], ['KPS'], ['Diário'], ['stewardship'], ['SPECIFICATIONS'], ['insp'], ['Dobermans'], ['Sgro'], ['eye-to-eye'], ['anti-caking'], ['airbrushed'], ['escargots'], ['Namibia'], ['bewitch'], ['AmTrust'], ['Dea'], ['Upcoming'], ['raven'], ['luggages'], ['judgmental'], ['billboard'], ['Slogans'], ['Bé'], ['Trenet'], ['Paltan'], ['Odescalchi'], ['Taffy'], ['43-48'], ['CodesEden4Hampers6'], ['Danu'], ['VNV'], ['sotho'], ['Thornville'], ['accepted.Blue'], ['Malley'], ['Ardara'], ['Gibco'], ['Rumpy'], ['4GL'], ['Kayakers'], ['Sake'], ['Hosley'], ['landmines'], ['expiry'], ['CLIO'], ['4,495'], ['Londra'], ['Crumpets'], ['Tanah'], ['0.075'], ['Minglewood'], ['bioanalytical'], ['Chocoholic'], ['Datacolor'], ['class-leading'], ['Me-TV'], ['givaway'], ['Basking'], ['second-to-none'], ['Lasithi'], ['Copyright'], ['visibility'], ['restlessjo'], ['Losinj'], ['openly'], ['TRIVIAL'], ['Reygadas'], ['Caz'], ['Wynns'], ['southern-style'], ['pit-bull'], ['Distel'], ['incise'], ['Tortie'], ['MECA'], ['Babolat'], ['Daughtry'], ['Aways'], ['Detente'], ['8877'], ['∴'], ['Buron'], ['Barbecues'], ['polyglot'], ['Hennepin'], ['BONDI'], ['20dB'], ['seclusion'], ['her.We'], [\"'Vine\"], ['P25'], ['originals'], ['Barnstable'], ['DiNovo'], ['GPIB'], ['BARS'], ['2017Find'], ['Darlin'], ['Losinj'], ['windage'], ['Bullies'], ['Dangdut'], ['Flore'], ['Oath'], ['Abraxane'], ['Babin'], ['Electrically'], ['More2'], ['PLAYBOY'], ['Spots'], ['Intergraph'], ['effectuated'], ['beefy'], ['Mdina'], ['Amps'], ['Chins'], ['painful'], ['post-9'], ['Doolin'], ['Thyme'], ['Tocris'], ['FirstCry.com'], ['Bruisers'], ['Prophetess'], ['Dilara'], ['Either'], ['Polestar'], ['LIVE1st'], ['bds'], ['CodesEden4Hampers6'], ['neg'], ['EaseLB1'], ['stumbled'], ['Emulsifiers'], ['1,907'], ['enforcement'], ['attracted'], ['photojournalism'], ['Endorsed'], ['isencrypted'], ['halftone'], ['Pitbulls'], ['explored'], ['aspic'], ['comparible'], ['butter-soft'], ['Starsky'], ['Capizzi'], ['Antena'], ['7M'], ['71.97CanvasAs'], ['Exciter'], ['Péronne'], ['pounced'], ['Charmingly'], ['Dll'], ['Anti-Theft'], ['QUEER'], ['30sec'], ['lonelier'], ['aways'], ['ProgramPosted'], ['vermillion'], ['Me-TV'], ['Kally'], ['Onsight'], ['Gayles'], ['IBAs'], ['30-10'], ['Luckenbach'], ['unique'], ['piggybacks'], ['must-stop'], ['CategoryAppetizers'], ['PetSitter.com'], ['Honfleur'], ['Trilingual'], ['Asham'], ['Arja'], ['Denish'], ['Nykaa'], ['Tippetts'], ['C.A.R.'], ['Shrove'], ['Collaboratively'], ['L.O.V.E'], ['News-Miner'], ['impurities'], ['Purrfect'], ['Mudpie'], ['Diatomaceous'], ['Rafferty'], ['volunteer-run'], ['Bloglovin'], ['Rinella'], ['Spiegeltent'], ['whitecaps'], ['Salute'], ['WPX'], ['uniques'], ['NAEA'], ['Neul'], ['doy'], ['sufficent'], ['allergies'], ['Seafront'], ['SOUL'], ['Expansys'], ['Boscawen'], ['Hochul'], ['LoveIn'], ['Beautycounter'], ['Fotodiox'], ['Štěpánek'], ['Equalities'], ['scarry'], ['Losinj'], ['territory'], ['sabe'], ['assertive'], ['Imprivata'], ['Praxair'], ['Bulluck'], ['Nooner'], ['bay'], ['Mckinley'], ['crosswords'], ['Rebranding'], ['pictographs'], ['disparagement'], ['spicier'], ['moieties'], ['Oath'], ['Losinj'], ['Mixology'], ['sistema'], ['Nimbuzz'], ['Eydie'], ['Dinkum'], ['ICNA'], ['Olixar'], ['FOM'], ['Hirer'], [\"'Amour\"], ['reignited'], ['Lahaul'], ['exposure.'], ['remov'], ['SAAM'], ['Externships'], ['winked'], ['Opelousas'], ['Istria'], ['Loon'], ['natively'], ['Tablescapes'], ['echo'], ['Nabs'], ['Thermomix'], ['Lootera'], ['AHAs'], ['Foursquare'], ['batteryLED'], ['softer'], ['EFTPOS'], ['torr'], ['tro'], ['Azamara'], ['Marketi'], ['tinting'], ['fishermen'], ['Billboards'], ['petroglyphs'], ['6th-8th'], ['Bookfair'], ['glossier'], ['Whitner'], ['W1F'], ['POISON'], ['photogenic'], ['literals'], ['Instructure'], ['Belmore'], ['Wanderlust'], ['Domicile'], ['saty'], ['Boudh'], ['Smokeless'], ['77S'], ['Broaden'], ['VNA'], ['niched'], ['FOUNDERS'], ['Wamberal'], ['ouzo'], ['lucks'], ['RESTAURANTS'], ['Unmissable'], ['DeRay'], ['Hoechlin'], ['airplay'], ['vapors'], ['0.125'], ['Multi-Site'], ['Deli'], ['phrasebook'], ['Plattsburg'], ['Rosary'], ['non-returnable'], ['Gayles'], ['SDCC'], ['Argosy'], ['postmarks'], ['23-day'], ['DeVita'], ['shinning'], ['Kaffe'], ['fall-off-the-bone'], ['PM-9'], ['narrow-mindedness'], ['Namibia'], ['Shades'], ['Learfield'], ['mIU'], ['Blogsite'], ['lockscreen'], ['guffaws'], ['Ardie'], ['vcore'], ['echo'], ['neg.'], ['allusive'], ['dekha'], ['echo'], ['huckleberry'], ['POUR'], ['panoramic'], ['displeasure'], ['Provo'], ['VMAX'], [\"'accueil\"], ['Matriculation'], ['Microsemi'], ['Videographers'], ['3,884'], ['HARMFUL'], ['tá'], ['1000X'], ['Krzyzewski'], ['Essence'], ['Amzer'], ['sass'], ['SiteRips'], ['Panaji'], ['Scarabeo'], ['Lorong'], ['Gaping'], ['5.3-inch'], ['L.L.Bean'], ['Compliments'], ['Darrelle'], ['Nicastro'], ['ruggedly'], ['Maaji'], ['Luce'], ['Ang-'], ['309.00'], ['AngiMouse'], ['Pictish'], ['Chere'], ['dot'], ['Caregiver'], ['Kix'], ['Crawdad'], ['Sportsmans'], ['Ezreal'], ['telefilms'], ['charge-'], ['Me-TV'], ['P95'], ['Flavours'], ['Backroads'], ['shiftiness'], ['Copywrite'], ['SAMA'], ['Losinj'], ['Dea'], ['sultanate'], ['MDGastroenterology'], ['bayou'], ['phosphor'], ['Farnese'], ['Kiya'], ['Foma'], ['CareLifestyle'], ['invaluable'], ['Luce'], ['Ginza'], ['jump-starting'], ['Waud'], ['Celebes'], ['Avnet'], ['toxin-free'], ['sympatico'], ['métro'], ['Britania'], ['Yacouba'], ['Fukunaga'], ['dysplastic'], ['Coteau'], ['Bermudas'], ['K-5th'], ['Diligently'], ['MSHA'], ['Pequeño'], ['Salty'], ['Panadol'], ['CodesEden4Hampers6'], ['Pulo'], ['RAMP'], ['IACP'], ['Recreated'], ['Prolife'], ['SystemRoot'], ['Gen2'], ['Rolfes'], ['Industry-Leading'], ['industry-recognized'], ['VNA'], ['branding'], ['MILO'], ['grittiness'], ['MoFo'], ['tranquillo'], ['Yat'], ['JUMPED'], ['unfamiliar'], ['GuidelinesPrivacy'], ['growl'], ['Laffy'], ['Ellenborough'], ['in-force'], ['Non-Fiction'], ['headhunting'], ['Nueva'], ['SOAK'], ['750s'], ['Graney'], ['Axxis'], ['echo'], ['per'], ['broadened'], ['Picnics'], ['McDunnough'], ['stanols'], ['Kafir'], ['Huckins'], ['isola'], ['SeaChange'], ['socioeconomics'], ['BringBackOurGirls'], ['broadened'], ['tan-lines'], ['Huntster'], ['Manzil'], ['smoking'], ['IGT'], ['14-28'], ['magnifying'], ['2Nite'], ['Kismet'], ['home.It'], ['Prasadam-Halls'], ['wikifipau.org'], ['Noom'], ['Gulam'], ['cowards'], ['ANYWHERE'], ['hyper-pigmentation'], ['Sail'], ['Sila'], ['Morong'], [\"'ree\"], ['anout'], ['decentralization'], ['Catriona'], ['unsucessful'], ['Rifa'], ['unwavering'], ['phylogeographic'], ['coved'], ['underbust'], ['Anniversaries'], ['DVM'], ['BookYou'], ['Laraine'], ['Asham'], ['namesakes'], ['Freebies'], ['whiteheads'], ['Shc'], ['joliet'], ['Carns'], ['co-starred'], ['pawprint'], ['Kookie'], ['9am-5pm'], ['Shearings'], ['CategoryAppetizers'], ['interferometric'], ['ABSURD'], ['palest'], ['firebrand'], ['Ern'], ['Martyred'], ['illegible'], ['Moree'], ['Apuan'], ['ARTISAN'], ['moieties'], ['-100'], ['Losinj'], ['MARPOL'], ['Syncretism'], ['unparalleled'], ['precios'], ['Amore'], ['Linois'], ['DNE'], ['Devitt'], ['Agapi'], ['luck'], ['Desserts'], ['Duas'], ['FLYFLV'], ['Provincetown'], ['équipée'], ['grilles'], ['MOBE'], ['PlayerUnknown'], ['43215'], ['telefilms'], ['Revlon'], ['cascara'], ['SearchBuy'], ['Abbott'], ['Fukunaga'], ['ipconfig'], ['genotype-phenotype'], ['Fujian'], ['Tuesday-Sunday'], ['euphonic'], ['Fons'], ['Seu'], ['All-District'], [',but'], ['echo'], ['northland'], ['Kally'], ['Serials'], ['4737'], ['Eastville'], ['Burdi'], ['200-800'], ['Snapcode'], ['libertatemamo'], ['Wirelessly'], ['Ricardos'], ['Ampat'], ['lnt'], ['Gen2'], ['Sirmione'], ['Vas'], ['Pulps'], ['Avati'], ['JUNEAU'], ['mozzies'], ['BARRINGTON'], ['JoinFind'], ['lightfast'], ['Cokie'], ['Obituaries'], ['Megger'], ['beleve'], ['Litha'], ['Gayles'], ['Veeam'], ['Immortalized'], ['Ultrasun'], ['innie'], ['SeaChange'], ['You'], ['Sparxxx'], ['jennings'], ['rezervaceDalší'], ['rubicon'], ['Arrowood'], ['Qu'], ['chewables'], ['Strengths'], ['Cohan'], ['Tried'], ['Pooch'], ['Slogans'], ['yote'], ['Advocate'], ['fronton'], ['misprint'], ['Tenzing'], ['Hepcat'], ['enchantingly'], ['ointments'], ['Selfies'], ['Amarula'], ['Sandakan'], ['NAMES'], ['meravigliosa'], ['Providenciales'], ['broad'], ['Gravitas'], ['Carmanah'], ['Guideposts'], ['smirk'], ['Fowey'], ['jumpstarting'], ['Redhook'], ['Beaumont'], ['Etruscans'], ['RentalsEnregistrer'], ['Soupy'], ['CategoryAppetizers'], ['HoJo'], ['2013Exhibit'], ['Unkown'], ['Yerba'], ['Shipwrecks'], ['Mudpie'], ['Buon'], ['40C'], ['BillionairesCelebrities'], ['iconoclasts'], ['EMPORIO'], ['AfroRomance'], ['torr'], ['Lard'], ['standardisation'], ['Kemo'], ['observe'], ['antis'], ['MugINR'], ['10am-3pm'], ['Warmoth'], ['federally'], ['Nyack'], ['caliphal'], ['stress-reduction'], ['Smarty'], ['Pageau'], ['misprint'], ['echo'], ['noontime'], ['Expressly'], ['ArchivesAll'], ['Chins'], ['Tenzing'], ['coon'], ['Copperplate'], ['seakeeping'], ['bylined'], ['CSUEB'], ['expanding'], ['Jammin'], ['Tainos'], ['OFFERING'], ['GSM-Forum'], ['Shipley'], ['Ramseur'], ['mid-1950'], ['x26'], ['locals'], ['darlin'], ['5616'], ['Geronimo'], ['sensing'], ['squinted'], ['off-putting'], ['AmTrust'], ['trespassers'], ['Unparalleled'], ['Simas'], ['Phước'], ['regionalization'], ['Hors'], ['Amzer'], ['McBratney'], ['dewdrop'], ['Apar'], ['pre-contact'], ['wwf'], ['chins'], ['winked'], ['crier'], ['crime-related'], ['WRAS'], ['Lorong'], ['intimidating'], ['Lower'], ['Hodges'], ['Facebook.com'], ['Sixpence'], ['piya'], ['Maaji'], ['attendees'], ['OYO'], ['Makassar'], ['petroglyphs'], ['Southernmost'], ['Carns'], ['NAPT'], ['offend'], ['decentralization'], ['murderously'], ['Doggie'], ['Leicas'], ['EDT2017-05-28'], ['PIER'], ['McCafe'], ['KOMO'], ['logue'], ['SWEEPSTAKES'], ['Wimps'], ['Quebe'], ['Datacolor'], ['Hassle'], ['soit'], ['signifies'], ['ComplaintVolunteerScheduleSubmit'], ['wickedlocal.com.'], ['EpisoDate.com.'], ['QCT'], ['gled'], ['Dumnonia'], ['industry-wide'], ['inspirational'], ['5,995'], ['Trespassing'], ['MarketsandMarkets'], ['Gravatar'], ['echo'], ['En-suite'], ['moieties'], ['NUVO'], ['echo'], ['flexibility'], [\"'Isonzo\"], ['Unita'], ['Me-TV'], ['detectible'], ['JetBrains'], ['Corradino'], ['Archangel'], ['Hunx'], ['perimenopause'], ['elusive'], ['wide'], ['Mesprit'], ['Prizes'], ['Nagini'], ['breather'], ['offer.We'], ['non-Greek'], ['Part.We'], ['echo'], ['Mudpie'], ['Together'], ['endorsement'], ['puck'], ['blueness'], ['Bangka'], ['Memebox'], ['Objective-C'], ['eos'], ['CodesEden4Hampers6'], ['crystal-clear'], ['Très'], ['FM2'], ['brung'], ['Highs'], ['bondsmen'], ['Gameplan'], ['favouritesEntry'], ['MiMo'], ['launched'], ['open-sourcing'], ['doubled'], ['Tushingham'], ['STORIESFamily'], ['200SX'], ['7QA'], ['.08'], ['omeprazole'], ['Masterclass'], ['lente'], ['joliet'], ['ReachLocal'], ['brighter'], ['kick-out'], ['MGNAlso'], ['Talisa'], ['MK-7'], ['Contesting'], ['photojournalistic'], ['smooths'], ['2015Our'], ['hoppin'], ['Bettys'], ['150x150px'], ['interspace'], ['2MP'], ['Depo-Provera'], ['Aways'], ['GuidelinesPrivacy'], ['Candra'], ['Bistip.com.'], ['Nasim'], ['Pendidikan'], ['85C'], ['Adare'], ['Kaleo'], ['NATIONWIDE'], ['Hapsburgs'], ['Jalsa'], ['decentralization'], ['nites'], ['Danker'], ['Proud'], ['A-K'], ['Malley'], ['Unparalleled'], ['solutions-oriented'], ['Spice'], ['Canacona'], ['Datacolor'], ['XC70'], ['a-z'], ['united'], ['Southborough'], ['headlights'], ['480mm'], ['Kuningan'], ['fiercely'], ['town-wide'], ['blinded'], ['Unbranded'], ['chief'], ['Cobrand'], ['Luce'], ['MX3'], ['IACP'], ['WBUR'], ['Teco'], ['CLOSEOUTS'], ['pets'], ['oxymoron'], ['BookExpo'], ['Fastly'], ['SMTnet'], ['Ovington'], ['Mudpie'], ['Lérins'], ['unenumerated'], ['Talan'], ['Googles'], ['ODNR'], ['At-Home'], ['Cader'], ['Cassel'], ['Jeffree'], ['insubstantial'], ['abso'], ['LVF'], ['Drapes'], ['MYO'], ['regionalization'], ['regionalization'], ['alum'], ['.m4r'], ['Jutes'], ['Utterly'], ['TRUSTe'], ['tradenames'], ['Petrarch'], ['Meribah'], ['CHORUS'], ['tattooers'], ['sandbar'], ['whiskering'], ['decentralization'], ['Dingmans'], ['quicken'], ['Gurganus'], ['Totale'], ['Booklovers'], ['Dannell'], ['Half-Day'], ['Yogurtland'], ['Progresso'], ['venerating'], ['ASIN'], ['Arakan'], ['foolhardy'], ['Oce'], [\"'Dwyer\"], ['Sonographer'], ['Yoli'], ['Porcello'], ['bootsWomen'], ['Petrel'], ['play-making'], ['DMACC'], ['inflamatory'], ['Agates'], ['Parikia'], ['fiercely'], ['Variety'], ['MSPCA'], ['Walked'], ['IceRays'], ['Michoacan'], ['0.999'], ['carjacked'], ['Shooting'], ['unmovable'], ['walk-ins'], ['promontories'], ['soulmate'], ['DeForest'], ['Marsaxlokk'], ['Britvic'], ['uniquely'], ['mls'], ['regionalization'], ['Pelikan'], ['sarcasm'], ['Lovingly'], ['Enlightened'], [\"'Armor\"], ['Neomycin'], ['Robach'], ['Smokin'], ['AVCA'], ['Intimidated'], ['17th-18th'], ['leviable'], ['Audited'], ['Cinemagic'], ['square-cut'], ['PROVEN'], ['PicturesFergie'], ['Sì'], ['propietary'], ['Lollobrigida'], ['surrendered'], ['NYDJ'], ['Transversal'], ['roche'], ['Swanny'], ['Sasak'], ['business-minded'], ['Freebies'], ['dual-LED'], ['COPIES'], ['Selatan'], ['Lamontagne'], ['Folegandros'], ['grantmaking'], ['Cajuns'], ['Stress-Free'], ['Quirk'], ['Attunity'], ['Vidi'], ['100dB'], ['Nippers'], ['0dB'], ['Co-curricular'], ['Rhu'], ['9.45am'], ['Jornal'], ['Torricelli'], ['HiSilicon'], ['Salty'], ['Purell'], ['whimpered'], ['Limitless'], ['MBC'], ['Chemin'], ['espoused'], ['.people'], ['engineering.jobs'], ['Carlon'], ['Pets'], ['Gozo'], ['score-team1-inns1'], ['TMCnet'], ['503rd'], ['R-rating'], ['Plumbob'], ['line.I'], ['pharmacogenetic'], ['Cowards'], ['bangor'], ['Navidad'], ['Motivation'], ['Perique'], ['cripplingly'], ['Parla'], ['Greet'], ['ITV2'], ['tiptoes'], ['shine'], ['Sizes'], ['craic'], ['anti-illegal'], ['Keisel'], ['29-10'], ['Ragdolls'], ['tala'], ['carbonates'], ['Bugles'], ['license'], ['QSR'], ['Yappy'], ['Trekker'], ['Dente'], ['Meryl'], ['repel'], ['windage'], ['seized'], ['Brandão'], ['double-digits'], ['Introvert'], ['tortie'], ['Tin'], ['R-rating'], ['Convenience'], ['Mug'], ['BULBS'], ['Strait'], ['Deizio'], ['2,746'], ['Phthalo'], ['friendlier'], ['broadened'], ['Etruscans'], ['TypeProductionOn'], ['Sambas'], ['phylogenetic'], ['disparagement'], ['Words'], ['Godspeed'], ['FirstCry.com'], ['Unmissable'], ['Jericoacoara'], ['birthmarks'], ['centreman'], ['Aloma'], ['Perdue'], ['Receptionist'], ['IPAs'], ['Cinemagic'], ['nearness'], ['Horoscopes'], ['sounded'], ['Tehreek'], ['t-butyl'], ['Maloy'], ['healing'], ['PALS'], ['Accurate'], ['Ishara'], ['Belong'], ['CnC'], ['AdMob'], ['Epting'], ['REMODELED'], ['Obagi'], ['immersion'], ['Nowell'], ['assim'], ['Mary-Anne'], ['regionalization'], ['alow'], ['unimaginable'], ['Frommers'], ['P24'], ['shelduck'], ['Durlston'], ['Bienvenue'], ['Contaminants'], ['Duse'], ['Akimbo'], ['Dorsoduro'], ['Rubenesque'], ['Karon'], ['pacing'], ['self-awareness'], ['Bogart'], ['rent-a-car'], ['Cinemagic'], ['Kantipur'], ['odorless'], ['Verbose'], ['phylogenetic'], ['escargots'], ['Kyron'], ['Tellyreviews1'], ['lipstick'], ['24mg'], ['Conversation.Travel'], ['Bikinis'], ['Decebalus'], ['Karisma'], ['Bodhi'], ['EMC'], ['X-Rite'], ['a.m.-7'], ['Beausoleil'], ['3ch'], ['food-stamp'], ['signage'], ['phylogeographic'], ['fbid'], ['FUNERAL'], ['mystique'], ['footlights'], ['nulla'], ['immersion'], ['jamais'], ['Mutrie'], ['sexiness'], ['Zealands'], ['CookEatShare'], ['Galvanize'], ['Fortean'], ['paua'], ['Leaded'], ['Regigigas'], ['tan-lines'], ['cedilla'], ['Monreale'], ['--------------------------------------------------'], ['Jeni'], ['Streeton'], ['heroics'], ['Ealdgyth'], ['pro-amnesty'], ['Ogunquit'], ['heeler'], ['rare'], ['3ch'], ['Heyjude'], ['FirstCry.com.'], ['Mahl'], ['GeeJo'], ['10X'], ['broadened'], ['Daughtry'], ['Notícias'], ['Elenore'], ['cinquefoil'], ['phylogeographic'], ['electorally'], ['Coco'], ['partnerships'], ['CTP'], ['FIMI'], ['cal'], ['Gene'], ['co-presenting'], ['BlogPaws'], ['Extech'], ['Nips'], ['Tasmin'], ['leapt'], ['Grace'], ['Fowey'], ['Sharper'], ['Me-TV'], ['wows'], ['POPCORN'], ['business-minded'], ['aggresively'], ['Selfies'], ['Pôle'], ['Huckabee'], ['www.amazon.com.'], ['DIAMOND'], ['dot'], ['Cyane'], ['highly-motivated'], ['Losinj'], ['shout'], ['Horoscopes'], ['Kayaking'], ['pro-amnesty'], ['APK'], ['examined'], ['ITV3'], ['geo-targeted'], ['coves'], ['Heraclitus'], ['markings'], ['Rovinj'], ['qHD'], ['Kweskin'], ['usefullness'], ['AD02'], ['Chins'], ['topicals'], ['5000K'], ['MMSI'], ['SPELLS'], ['Horoscopes'], ['Ivi'], ['Participating'], ['skys'], ['Adore'], ['Gorlin'], ['Wak'], ['Insha'], ['Exhibitor'], ['MarketPlace'], ['45-5'], ['etched'], ['Inspirations'], ['Inspirations'], ['Allahu'], ['digitals'], ['unlikley'], ['cornwall'], ['aquavit'], ['16nm'], ['Agfa'], ['off-premises'], ['Nerello'], ['510'], ['Proteomics'], ['Gardenerfrom'], ['phylogeographic'], ['SPONSORSHIP'], ['polyatomic'], ['Liquorice'], ['Duméril'], ['Portuguese'], ['distortion-free'], ['Sutliff'], ['Neals'], ['Mérida'], ['geos'], ['sassiness'], ['vine'], ['Murguía'], ['Casemate'], ['outdistance'], ['30sec'], ['Whiskeys'], ['available.Review'], ['Bali'], ['10L'], ['wynn'], ['something'], ['Hickory'], ['ever-lasting'], ['40-49'], ['EventsNo'], ['nasturtiums'], ['Patties'], ['hio'], ['10am-2pm'], ['spiciest'], ['Wonderfalls'], ['Portraits'], ['150C'], ['CreditMantri'], ['etch'], ['Vili'], ['weeklies'], ['Doggie'], ['Wazee'], ['OGL'], ['Fearlessly'], ['birthmarks'], ['DualDisc'], ['Roundstone'], ['albergue'], ['Superior'], ['STINKS'], ['Très'], ['Mums'], ['voltmeter'], ['Koup'], ['likers'], ['MALTA'], ['Suntec'], ['Sixes'], ['cut-glass'], ['Newk'], ['finders'], ['Forefathers'], ['Brocka'], ['2012Well'], ['EnglandG.1'], ['upperhand'], ['wood-beamed'], ['Sullivans'], ['A-M'], ['Specialise'], ['FashionMiranda'], ['Nirvana'], ['Veneti'], ['skeered'], ['Masereel'], ['Jumpin'], ['Pera'], ['Scrapy'], ['FamilyFun'], ['Houthis'], ['restlessjo'], ['Vidi'], ['SPCA'], ['goo-free'], ['Multilingual'], ['vapors'], ['inAboutSearchSign'], ['Pauley'], ['Bulu'], ['c-stores'], ['Selena'], ['Didgeridoo'], ['54Location'], ['‒'], ['Gen2'], ['Tokyogirl79'], ['Rub'], ['thumbwheel'], ['Tumultuous'], ['phenocrysts'], [\"'Urville\"], ['IFSEC'], ['Rehoming'], ['affiliations'], ['Internship'], ['Marari'], ['Guides'], ['Hospitality'], ['Pittman'], ['DCR'], ['conservatives'], ['emblazoned'], ['dell.com'], ['extinguished'], ['re'], ['misprint'], ['carryforwards'], ['swag'], ['DNovember'], ['3ch'], ['whis'], ['wickedlocal.com.'], ['area.See'], ['Charice'], ['Sangoma'], ['Sadeghi'], ['ProShares'], ['Praa'], ['capitalized'], ['SEVIS'], ['joie'], ['Heyjude'], ['brid'], ['coveted'], ['Periodontal'], ['TLB'], ['Bogert'], ['assays'], ['Leatherwood'], ['Mudpie'], ['Oland'], ['mazel'], ['Polícia'], ['ValuesRebates'], ['8.30pm'], ['Quad'], ['VICTORY'], ['ZEE'], ['Delightfully'], ['Bollards'], ['Mellanox'], ['Litoria'], ['Wolfcamp'], ['Betong'], ['Newborough'], ['Catseye'], ['blazing'], ['pam'], ['Guider'], ['Quantitative'], ['GalleryYou'], ['Knorr'], ['Mediatrix'], ['2914'], ['pureness'], ['Yem'], ['Secreto'], ['Womanly'], ['ACE2'], ['Seagrove'], ['Moosa'], ['goldens'], ['FaithWriters'], ['Picnics'], ['Lusitano'], ['Bogan'], ['Woolgoolga'], ['Kriseman'], ['cTnT'], ['Losinj'], ['3.2M'], ['staters'], ['Chocolates'], ['Tuesday-Sunday'], ['SPONSORSHIP'], ['dialect'], ['5,995'], ['quickening'], ['raza'], ['Christmann'], ['Glaciology'], ['Royalists'], ['saltwater'], ['Sniff'], ['Arbonne'], ['phenocrysts'], ['Aways'], ['LinuxQuestions.org'], ['MidwayUSA'], ['Fredda'], ['Canoeing'], ['Axios'], ['unbeliever'], ['Bandelier'], ['Llandudno'], ['blazes'], ['Spofforth'], ['cardiomyopathy'], ['Inkwell'], ['KL'], ['chien'], ['Lastovo'], ['Unsurpassed'], ['Walk-ins'], ['Purrs'], ['PinterestView'], ['Fotolog'], ['Uncirculated'], ['friendlier'], ['tan-lines'], ['regionalization'], ['debateable'], ['friendlier'], ['ISSI'], ['anti-gambling'], ['Giada'], ['Allons'], ['phylogeographic'], ['77S'], ['Inne'], ['Snappers'], ['800mhz'], ['1,000,000.00'], ['SolderingWork'], ['Teambuilding'], ['Cubans'], ['DINER'], ['Pinteres'], ['moon'], ['underexposure'], ['Grouse'], ['OKC'], ['Stripers'], ['Baptisms'], ['Misunderstood'], ['Doire'], ['for.Advanced'], ['wickedlocal.com.'], ['Salvini'], ['consistancy'], ['Blogsite'], ['Heddon'], ['Rosemead'], ['Deb'], ['Chulo'], ['publishers'], ['LROC'], ['harv'], ['3ch'], ['Fredda'], ['Micca'], ['doubled'], ['Ang-'], ['mushers'], ['Deli'], ['Smeared'], ['S-S'], ['information.4.5'], ['Jeni'], ['semaine'], ['Olbermann'], ['4ohms'], ['Oyu'], ['MCACC'], ['lookout'], ['becquerels'], ['0444'], ['Caicos'], ['DPReview'], ['roamers'], ['campers'], ['resumes'], ['Lothrop'], ['immunoassays'], ['Cremated'], ['Rounder'], ['Plumbago'], ['Antiparos'], ['mein'], ['parting'], ['499.00'], ['Mountfort'], ['microondas'], ['halloumi'], ['400-700'], ['ohms'], ['Prego'], ['iFrames'], ['Mums'], ['Hanen'], ['aperature'], ['Evanescence'], ['Buon'], ['Vapor4Life'], ['DONUTS'], ['Zumbo'], ['ADOPTION'], ['PYREX'], ['Mercouri'], ['Nek'], ['limpo'], ['Phrases'], ['Tilsit'], ['clien'], ['f-stop'], ['ashed'], ['RICHARDSON'], ['Müzik'], ['Steinle'], ['Marinades'], ['BRAVO'], ['Starwest'], ['Licensees'], ['TOURIST'], ['Kindness'], ['SERPS'], ['bowhunter'], ['assest'], ['santa'], ['moobs'], ['non-selective'], ['Samphire'], ['furigana'], ['co-exists'], ['Siddharta'], ['dual-band'], ['noncompulsory'], ['light.It'], ['JUNCTION'], ['Linny'], ['Magnify'], ['Hikers'], ['A-pillars'], ['doubly'], ['BreakfastPlats'], ['Dovey'], ['Breau'], ['Disgusting'], ['DenizDevOps'], ['publishers'], ['Gooseberry'], ['U-test'], ['FIESTA'], ['3BB'], ['goldmines'], ['brava'], ['holidayinnexpress.com'], ['Vidi'], ['Vidi'], ['LVF'], ['Badshah'], ['Immeasurable'], ['Hors'], ['SRT'], ['Whitsundays'], ['Phrases'], ['Frommers'], ['Aways'], ['Hellos'], ['Skink'], ['Arambol'], ['Tava'], ['Picnicking'], ['Onika'], ['Snooky'], ['Lamontagne'], ['Reblog'], ['1-way'], ['favouritesEntry'], ['Poblanos'], ['pureness'], ['Prized'], ['Lollies'], ['Frankland'], ['Tins'], ['Self-Publish'], ['LVF'], ['Taffy'], ['Mastectomy'], ['IIPA'], ['Kally'], ['focals'], ['golds'], ['smoked'], ['girl-next-door'], ['Geaux'], ['nothing.It'], ['nowWomen'], ['Wog'], ['Imperials'], ['broadened'], ['soulfulness'], ['Punchline'], ['JacketFlap'], ['Watercolors'], ['aRead'], ['ABP'], ['glitz'], ['abut'], ['ClickBank'], ['GooglePlus'], ['done.What'], ['distortion-free'], ['Kepner'], ['Vapor4Life'], ['rebrand'], ['pockmarks'], ['Womanly'], ['Jades'], ['plexi-glass'], ['TBA'], ['Freebies'], ['Reata'], ['on-staff'], ['Paleface'], ['wheelhouse'], ['Bloomsbury'], ['Patties'], ['Innova'], ['EXPOSURE'], ['Owed'], ['Hazaribagh'], ['Skinz'], ['particulièrement'], ['Rotel'], ['Rifka'], ['Ang-'], ['Jacquet'], ['Rockhouse'], ['DIPA'], ['Inkwell'], ['Dentures'], ['proud'], ['Thermage'], ['dark.The'], ['ONYX'], ['paddler'], ['Territory'], ['Kustom'], ['us.What'], ['Ete'], ['midpalate'], ['AHPRA'], ['Witherell'], ['enthral'], ['McAlexander'], ['DP2'], ['chimenea'], ['sandbar'], ['1-888-BEST'], ['ZEE'], ['dark-colored'], ['11,12'], ['humectant'], ['cata'], ['adhere'], ['BookSurfCamps'], ['Wildcrafted'], ['Darkroom'], ['version10.1.0'], ['Sancti'], ['CheapOair'], ['Pro-Kit'], ['Foslien'], ['Totnes'], ['jovi'], ['Wafd'], ['Gwynedd'], ['AngelesOaklandFort'], ['gyuto'], ['ACTFL'], ['Priscilla'], ['Ovations'], ['SeaChange'], ['PTY'], ['10M'], ['Bienvenidos'], ['StorSimpleLower'], ['grouphug'], ['offish'], ['salty'], ['PlayerUnknown'], ['TravellerDestinationsFeaturesFood'], ['MondayTuesdayWednesdayThursdayFridaySaturdaySundayYou'], ['Ditta'], ['JobsOhio'], ['be'], ['well-draining'], ['Bundanoon'], ['MESSENGER'], ['Spofforth'], ['Me-TV'], ['Kalender'], ['Murguía'], ['prix-fixe'], ['lineup'], ['Elenore'], ['Performances'], ['AGPL'], ['added.Italy'], ['Ilfracombe'], ['639-1'], ['Dennings'], ['Sailing'], ['Dromoland'], ['IPAs'], ['Pardy'], ['Pulo'], ['PITT'], ['Zumbo'], ['Heintz'], ['FRIENDS'], ['Heyjude'], ['Unitrends'], ['500-year-old'], ['Daddo'], ['IACP'], ['kit.'], ['Harbourside'], ['RINOs'], ['Cecy'], ['ProgramPosted'], ['Grads'], ['Ô'], ['ofer'], ['Horoscopes'], ['HARMAN'], ['Bewitching'], ['Bivouac'], ['madly'], ['Preseli'], ['on-the-water'], ['bilingually'], ['never'], ['Talend'], ['enticingly'], ['lightfast'], ['InformationWe'], ['ReplyDeleteTiffany'], ['B4.svg'], ['Marari'], ['Gool'], ['IPAs'], ['brine'], ['assays'], ['signify'], ['drumhead'], ['somethi'], ['BookSurfCamps'], ['PMSA'], ['WRKO'], ['min'], ['Dare'], ['MENTOR'], ['nur'], ['cartoonists'], ['Spotlighting'], ['TG4'], ['2K'], ['Ampat'], ['Medica'], ['UsWebsite'], ['Postpaid'], ['3MP'], ['1705260'], ['Hemu'], ['hCG'], ['dialect'], ['Halfway'], ['Donn'], ['piu'], ['Dubrovačko-neretvanska'], ['no-man'], ['Motorplex'], ['mukti'], ['Ancora'], ['crispest'], ['Unmistakable'], ['Fontenot'], ['Collen'], ['pronouced'], ['Avène'], ['Nian'], ['Huon'], ['Bettys'], ['Piazzi'], ['fluent'], ['Spyderco'], ['Babbacombe'], ['all-encompassing'], [\"'Isola\"], ['LCT'], ['obscenity'], ['wilds'], ['IACP'], ['stoup'], ['squinted'], ['Chatto'], ['smoking'], ['judgemental'], ['RestaurantsRestaurants'], ['tig'], ['Wuornos'], ['consistantly'], ['Plaka'], ['oand'], ['Vel'], ['Telit'], ['Langit'], ['Beginning'], ['Gayheart'], ['IPPY'], ['Neals'], ['I-87'], ['rafflecopter'], ['vermillion'], ['PATIO'], ['middle-of-the-road'], ['Glam'], ['ConductTerms'], ['Boundless'], ['squelch'], ['DoctorsDr'], ['Cok'], ['QSL'], ['Stratevi'], ['Blasphemy'], ['four-speed'], ['SpotHero'], ['Harroun'], ['Deli'], ['moxy'], ['Unconditional'], ['wht'], ['Savoring'], ['ouvre'], ['financeUniversity'], ['phenocrysts'], ['Gohar'], ['Mandira'], ['Vidi'], ['Himachal'], ['Reilley'], ['internationals'], ['Babymoon'], ['B50'], ['Salada'], ['TRP'], ['unlikley'], ['Vraiment'], ['flagstones'], ['furever'], ['tumultuous'], ['FLYFLV'], ['bloodhounds'], ['HMB'], ['Tava'], ['Chavacano'], ['Arapiles'], ['Certifications'], ['anywere'], ['CSPP'], ['NMCA'], ['R2'], ['inscription'], ['Sportsmans'], ['Smeared'], ['Makassar'], ['SitePoint'], ['0.375'], ['batteryLED'], ['Palestina'], ['sandbanks'], ['JAPW'], ['over.Never'], ['unduplicated'], ['8.30pm'], ['Deborah'], ['HomeForumArticlesItalian'], ['Hazlewood'], ['Misti'], ['feuded'], ['cetainly'], ['있습니다'], ['waht'], ['Maaji'], ['Nusa'], ['NewNew'], ['48W'], ['preditors'], ['cer'], ['Menorca'], ['Silda'], ['Carbis'], ['Mugshots.com'], ['overfill'], ['Hound'], ['Casemate'], ['Rifa'], ['Twillingate'], ['Hobbema'], ['Cremated'], ['EntriesJob'], ['599.99'], ['Priceline'], ['formidable'], ['Charme'], ['tolerence'], ['Lecturers'], ['affectionate'], ['Surveillance'], ['B4.svg'], [\"'automne\"], ['Ci'], ['SAILOR'], ['SOLD'], ['Rexona'], ['Ang-'], ['amor'], ['pre-incubation'], ['Carvel'], ['Alabaster'], ['Listerine'], ['showbiz'], ['Dew'], ['dI'], ['phenocrysts'], ['substance-abuse'], ['Jillson'], ['Phrases'], ['yuor'], ['barbacoa'], ['micro-breweries'], ['warts-and-all'], ['F2.0'], ['USP'], ['cozier'], ['Bairstow'], ['Wilcher'], ['Nipper'], ['Meshell'], ['Xlibris'], ['Refundable'], ['midrange'], ['Speightstown'], ['Griswaldo'], ['PSMA'], ['UNCONDITIONAL'], ['CROOKED'], ['M.E.N.'], ['SSAE'], ['high-ISO'], ['irwin'], ['Registration'], ['Roadblocks'], ['Mountfort'], ['Syrena'], ['Jeni'], ['westernmost'], ['ProMaster'], ['gaurantee'], ['aventurine'], ['Salone'], ['phylogenetic'], ['Ametek'], ['Piegan'], ['Tutus'], ['talisman'], ['Peyroux'], ['Smeg'], ['hct'], ['isola'], ['Beckwourth'], ['Rinca'], ['Koffee'], ['1,737'], ['Tonquin'], ['Skin-Care'], ['cme'], ['Cahoots'], ['phenocrysts'], ['unlikley'], ['friendlier'], ['bashful'], ['Tantalize'], ['minded'], ['seperation'], ['Türk'], ['Cracked'], ['FSc'], ['SGCM'], ['ListMake'], ['LSPR'], ['Burqa'], ['AVON'], ['unlikley'], ['picante'], ['Maura'], ['phenocrysts'], ['Gaping'], ['Spit'], ['Crossways'], ['horizontals'], ['Bou'], ['Amore'], ['Duncannon'], ['ReadTrump'], ['77S'], ['saty'], ['carnality'], ['Smores'], ['Victorio'], ['lithos'], ['TREATS'], ['THR'], ['Doxy'], ['Remparts'], ['Congrat'], ['intimidating'], ['VOC'], ['offputting'], ['R-rating'], ['Prudhomme'], ['SOUP'], ['pawrents'], ['hop-off'], ['Craic'], ['Spectrophotometers'], ['IPPY'], ['non-New'], ['Maulana'], ['Sifnos'], ['Moçambique'], ['Nove'], ['Whoopie'], ['Line-Up'], ['KWPN'], ['emulated'], ['Allmand'], ['30sec'], ['Phrases'], ['3.5g'], ['Gaspereau'], ['ArticlesPopular'], ['Jarawa'], ['Thigpen'], ['unlikley'], ['Vocally'], ['Horoscopes'], ['Cayucos'], ['searchAll'], ['OfficeTeam'], ['voda'], ['Smorgasbord'], ['Thee'], ['Frommers'], ['Hoi'], ['unlikley'], ['Gen2'], ['insp'], ['Shame'], ['Regency'], ['glowed'], ['Sorriso'], ['tortie'], ['acrobat'], ['iki'], ['Elephanta'], ['ABCs'], ['FindMugshots.com'], ['Terrence'], ['bacony'], ['Newsmagazine'], ['passeggiata'], ['denotations'], ['phenocrysts'], ['SlovenščinaMeter'], ['Freebies'], ['vertHjelpMeld'], ['Vintners'], ['glowing'], ['Brockport'], ['Snee'], ['violent'], ['Nahi'], ['CELEBRATING'], ['PILL'], ['GuidelinesPrivacy'], ['Phrases'], ['12.5'], ['overstepping'], ['Feisty'], ['ESI-MS'], ['cbet'], ['Pomerania'], ['be.It'], ['CategoryAppetizers'], ['OPPO'], ['massunsolicited'], ['end.It'], ['Consulate'], ['sea'], ['jawline'], ['castel'], ['samplings'], ['benefi'], ['deprecated'], ['Faintly'], ['Dare'], ['Prev'], ['Rounder'], ['Tainos'], ['Helgenberger'], ['I-93'], ['episode.S01E03'], ['xo'], ['Crees'], ['Lusa'], ['K9s'], ['phylogeographic'], ['Honfleur'], ['Chins'], ['DPT'], ['Camonica'], ['encyclopedia-worthy'], ['Founders'], ['-rankedSee'], ['minstrelsy'], ['CommentLuv'], ['olivine'], ['DIGITAL'], ['Perique'], ['Horseracing'], ['Akimbo'], ['Silvermoon'], ['voidness'], ['24-28'], ['Masereel'], ['dotted'], ['Spyderco'], ['Microflex'], ['CAMFormulas.com'], ['PILL'], ['telefilms'], ['Selinunte'], ['mazing'], ['royalty'], ['FacebookView'], ['Taffy'], ['Bouguer'], ['lightfast'], ['vermillion'], ['Brokered'], ['Mozi'], ['irreverence'], ['Monday-Saturday'], ['Heckler'], ['DOA'], ['Imodium'], ['Inuits'], ['cutting-edge'], ['gyno'], ['Bronze'], ['saline'], ['Bafana'], ['Suitcases'], ['Staffs'], ['pureness'], ['1705230'], ['assayed'], ['Basse-Normandie'], ['snowfields'], ['ChangeBrake'], ['Rozay'], ['off-hook'], ['my-bio-zen'], ['Wallcoverings'], ['yours'], ['LifestylePolitical'], ['use-by'], ['fumaroles'], ['NY--'], ['Whalers'], ['unmanageable'], ['Saje'], ['Sorento'], ['Sidhe'], ['LEMONADE'], ['Hobie'], ['Frankenreiter'], ['Whinney'], ['wouldn'], ['said'], ['Casemate'], ['Coppers'], ['Phrases'], ['Info.'], ['Haggle'], ['pets'], ['ethidium'], ['strength'], ['KX3'], ['650b'], ['photosphere'], ['backbones'], ['gunwales'], ['smokefree'], ['Allons'], ['Vicolo'], ['Syndication'], ['familiarized'], ['xoxoKarenaArt'], ['Lappy'], ['aloha'], ['evidence-based'], ['voda'], ['WQAM'], ['mesmerise'], ['Sutch'], ['Robertsons'], ['six-character'], ['Moki'], ['WINNERS'], ['Hep'], ['Diggity'], ['photojournalism'], ['contentment'], ['Nancie'], ['fines'], ['best-in-class'], ['Myrina'], ['Buhle'], ['rpm'], ['Roberge'], ['proches'], ['Deli'], [\"'Entremont\"], ['Hinda'], ['dogtooth'], ['phenocrysts'], ['mout'], ['Karon'], ['APPO'], ['authentically'], ['Hanukkah'], ['Buddah'], ['ABP'], ['Kaela'], ['quitted'], ['Quindío'], ['Babel'], ['Amidah'], ['Younique'], ['roche']]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target words:\n",
      " [['SXU'], ['Rautela'], [\"'Doul\"], ['1597'], ['Erath'], ['Story'], ['Strief'], ['Wieber'], ['8060'], ['Scot-Irish'], ['Aubagne'], ['Nuevo'], ['a-z'], ['Linchpin'], ['A-to-Z'], ['Inkwell'], ['AGMA'], ['PIER'], ['Beltrami'], ['Famille'], ['Share24'], ['DPO'], ['Pastorale'], ['Medica'], ['Karbon'], ['infringers'], ['mbar'], ['Birchmere'], ['Birders'], ['Journeying'], ['JULIET'], ['Ruang'], ['00ZTerrific'], ['pressings'], ['www.copyright.gov'], ['live-out'], ['Trollfest'], ['Moring'], ['Jeffersonian'], ['Prescriptives'], ['lontano'], ['BookMeditationRetreats'], ['JT65'], ['Kybella'], ['goalkeepers'], ['Kally'], ['Bx'], ['Steinle'], ['fearlessness'], ['Superchips'], ['Olindo'], ['fido'], ['bilis'], ['Mocca'], ['UsFrom'], ['clpo13'], ['Neverwhere'], ['NYRelated'], ['Whitesville'], ['Appalachians'], ['Lopo'], ['PENTAX'], ['Vivre'], ['Screaming'], ['drosupport'], ['AWAY'], ['Rebeck'], ['2-30'], ['GBS'], ['PRE-OWNED'], ['Melior'], ['nmol'], ['boundary-pushing'], ['Lumineers'], ['Shea-Porter'], ['LIMA'], ['SERENITY'], ['low-tax'], ['MCACC'], ['RAPP'], ['sub-1'], ['Cumulus'], ['Waitress'], ['peacekeepers'], ['push'], ['USC'], ['IDed'], ['Ellender'], ['Un-American'], ['Monographie'], ['Nightmares'], ['colourblind'], ['510'], ['Dubie'], ['Vagrants'], ['Shved'], ['darkest'], ['P600'], ['unmovable'], ['kayakers'], ['Pentax'], ['bikin'], ['Gielgud'], ['Redheads'], ['too.Happy'], ['Bilingual'], ['Koroit'], ['10021'], ['Sainte-Chapelle'], ['Re-entry'], ['Rahon'], ['Mandolins'], ['day-and-date'], ['SPICY'], ['myself.It'], ['Mandolins'], ['abolitionism'], ['XL25'], ['FARMHOUSE'], ['Holiday'], ['Weatherby'], ['Rosebank'], ['uncomfortably'], ['revamping'], ['Participatory'], ['FEAT'], ['BOURBON'], ['Achievable'], ['Latent'], ['Bayle'], ['Roscoff'], ['Do-not-call'], ['Cuca'], ['Lossless'], ['Auger'], ['Conanicut'], ['Beaucoup'], ['ruggedly'], ['UNCONDITIONAL'], ['Walgreens.com'], ['enablement'], ['Condemned'], ['DelBene'], ['Kilham'], ['clarity'], ['petroglyphs'], ['Non-US'], ['CloudFront'], ['seasonAvailable'], ['Plath'], ['teetotalers'], ['PMOrchids'], ['StazOn'], ['Bethancourt'], ['Bloodletting'], ['NTD'], ['blog.wikimedia.org'], ['backstabbers'], ['says.He'], ['gunwale'], ['well-rated'], ['TodaysiPhone'], ['residency'], ['chargeability'], ['17-40'], ['Carte'], ['Inday'], ['30sec'], ['Lampanelli'], ['grub.cfg'], ['Fingerprinting'], ['showcase'], ['Lybrate.com.'], ['open-ended'], ['Barbadians'], ['Selecta'], ['CatholicMom.com'], ['windsurfers'], ['Hasselblad'], ['ROIs'], ['SexHoroscopesHot'], ['oou'], ['Two-step'], ['Embraced'], ['GROG'], ['Festo'], ['volcanism'], ['Samick'], ['re-enact'], ['Clients'], ['NMR'], ['area.We'], ['Error.Please'], ['Phosphor'], ['Sweetland'], ['RSV'], ['Rofo'], ['Mimmo'], ['booksellers'], ['preeclampsia']]\n",
      "evaluation of source language de: average cosine= -0.0068361242289250185 accuracies are p@1=0.0, \n",
      "Epoch  11 / 100\n",
      "Progress:  712.70245 1.9070103\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 660.6636\n",
      "Epoch  12 / 100\n",
      "Progress:  712.7782 1.9042051\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 658.6274\n",
      "Epoch  13 / 100\n",
      "Progress:  713.4041 1.896985\n",
      "Summed abs weights Generator: 4310.838\n",
      "Summed abs weights Discrimi.: 656.7112\n",
      "Epoch  14 / 100\n",
      "Progress:  713.8269 1.8938565\n",
      "Summed abs weights Generator: 4310.838\n",
      "Summed abs weights Discrimi.: 655.59326\n",
      "Epoch  15 / 100\n",
      "Progress:  713.49725 1.8948858\n",
      "Summed abs weights Generator: 4310.838\n",
      "Summed abs weights Discrimi.: 654.3486\n",
      "Epoch  16 / 100\n",
      "Progress:  713.67523 1.8902216\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 653.26245\n",
      "Epoch  17 / 100\n",
      "Progress:  714.19794 1.8939419\n",
      "Summed abs weights Generator: 4310.8374\n",
      "Summed abs weights Discrimi.: 652.715\n",
      "Epoch  18 / 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-085e94c8d042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# execute only if run as a script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-085e94c8d042>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0midx_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnr_trgt_langs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mx_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Generate fake data aka translate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx_to\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;31m#print('Preds:', y_preds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Uni/MasterAI/LTP/Project/Repo/language-technology-project/model/gan.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    importlib.reload(gan)\n",
    "    \n",
    "    NLLLoss = torch.nn.NLLLoss()\n",
    "    nr_src_langs = len(languages['src'])\n",
    "    nr_trgt_langs = len(languages['trgt'])\n",
    "    nr_langs = nr_src_langs + nr_trgt_langs\n",
    "    print('Nr source languages:', nr_src_langs)\n",
    "    print('Nr target languages:', len(languages['trgt'])) \n",
    "    print('\\n', languages)\n",
    "    \n",
    "    if avg_grads:\n",
    "        avg_factor = 1/nr_src_langs\n",
    "        print('Decoder gradient averaging factor:', avg_factor, \"\\n\")\n",
    "    \n",
    "    # Get bilingual dictionary for evaluating train loss or at least testing\n",
    "    dicts = dict()\n",
    "    #TODO\n",
    "\n",
    "    # Set up model architecture\n",
    "    #net = gan.GAN(embedding_dim, internal_dim, output_dim, mode=gan_mode, languages['src'])\n",
    "    net = gan.GAN(embedding_dim, internal_dim, output_dim, mode=gan_mode)\n",
    "    \n",
    "    if gan_mode == 'linear':\n",
    "        net.generator.beta = 0.001 # Stepsize in making generator orthogonal\n",
    "        for i in range(10000):\n",
    "            # Perform incremental orthogonalization\n",
    "            net.generator.orthogonalize()\n",
    "    \n",
    "    # Get optimizers; 1 per source language of encoder and 1 for discriminator\n",
    "    optimizers = {'gen': {}}\n",
    "    \n",
    "    if gan_mode == 'nonlinear':\n",
    "        for lang in languages['src']:\n",
    "            optimizers['gen'][lang] = torch.optim.Adam([{'params': net.generator.encoders[lang].parameters()},\n",
    "                                                        {'params': net.generator.decoder.parameters()}\n",
    "                                                       ],\n",
    "                                                        lr=0.001, betas=(0.9, 0.999), eps=1e-08, \n",
    "                                                        weight_decay=0.0, amsgrad=False)\n",
    "    elif gan_mode == 'linear':\n",
    "        optimizers['gen'] = torch.optim.Adam(net.generator.parameters(),\n",
    "                                                    lr=0.001, betas=(0.9, 0.999), eps=1e-08, \n",
    "                                                    weight_decay=0.02, amsgrad=True)\n",
    "    optimizers['dis'] = torch.optim.Adam(net.discriminator.parameters(),\n",
    "                                         lr=0.0001, betas=(0.9, 0.999), eps=1e-08, \n",
    "                                         weight_decay=0.02, amsgrad=True)\n",
    "    \n",
    "    # Train\n",
    "    train_loss_gen, train_loss_dis = [], []\n",
    "    eval_loss = [] # TODO: To be populated...\n",
    "    last_loss = -1\n",
    "    \n",
    "    es = EarlyStopping(patience=10) #patience = amount of epochs the loss has to stop decreasing in a row for it to early stop\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch ', epoch, '/', epochs)\n",
    "        loss_gen, loss_dis = 0., 0.\n",
    "\n",
    "        # Train #\n",
    "        for batch in range(num_minibatches):\n",
    "            #print('Epoch ', epoch, ', Batch ', batch, '/', num_minibatches)\n",
    "            \n",
    "            # Update discriminator #\n",
    "            net.discriminator.train()\n",
    "            net.generator.eval()\n",
    "            net.discriminator.zero_grad()\n",
    "            \n",
    "            # Retrieve data\n",
    "            x = get_train_data(languages, vocabs, batch_size)#.to(device) \n",
    "\n",
    "            # Init data-storage\n",
    "            y_preds = torch.zeros([nr_langs*batch_size, 2])\n",
    "            y_true = torch.zeros([nr_langs*batch_size]).long()\n",
    "            \n",
    "            y_true[0:batch_size] = real_label  # First elements are target embeddings\n",
    "\n",
    "            \n",
    "            # All-real minibatch\n",
    "            x_real = x[languages['trgt'][0]]  # Extract all-real data\n",
    "            y_preds[0:batch_size] = net.discriminator(x_real)\n",
    "            \n",
    "            # All-fake minibatches - One minibatch per source language\n",
    "            if gan_mode == 'nonlinear':\n",
    "                for i, language in enumerate(languages['src']):\n",
    "                    idx_from = batch_size*i+batch_size*nr_trgt_langs\n",
    "                    idx_to = batch_size*(i+1)+batch_size*nr_trgt_langs\n",
    "                    x_trans = net.generator(x[language], language)  # Generate fake data aka translate\n",
    "                    y_preds[idx_from:idx_to] = net.discriminator(x_trans)\n",
    "                #print('Preds:', y_preds)\n",
    "\n",
    "                # Loss proportional to discriminator's probability of correctly distinguishing TP and FP\n",
    "                loss = NLLLoss(torch.log(y_preds+0.0000001), y_true)  # NLLLoss needs log(prob_distribution); adding small amount to avoid log(0)\n",
    "                loss.backward()    # Compute gradients only for discriminator\n",
    "                loss_dis += loss\n",
    "                \n",
    "            elif gan_mode == 'linear':\n",
    "                for i, language in enumerate(languages['src']):  # only one here\n",
    "                    idx_from = batch_size*i+batch_size*nr_trgt_langs\n",
    "                    idx_to = batch_size*(i+1)+batch_size*nr_trgt_langs\n",
    "                    x_trans = net.generator(x[language])  # Generate fake data aka translate\n",
    "                    y_preds[idx_from:idx_to] = net.discriminator(x_trans)\n",
    "                #print('Preds:', y_preds)\n",
    "\n",
    "                # Loss proportional to discriminator's probability of correctly distinguishing TP and FP\n",
    "                loss = NLLLoss(torch.log(y_preds+0.0000001), y_true)  # NLLLoss needs log(prob_distribution); adding small amount to avoid log(0)\n",
    "                loss.backward()    # Compute gradients only for discriminator\n",
    "                loss_dis += loss\n",
    "                net.generator.orthogonalize()\n",
    "            \n",
    "            # Weight update for discriminator\n",
    "            optimizers['dis'].step() \n",
    "\n",
    "            \n",
    "            # Update generator #\n",
    "            net.generator.train()\n",
    "            net.discriminator.eval()\n",
    "            net.generator.zero_grad()\n",
    "            \n",
    "            # Retrieve data\n",
    "            x = get_train_data(languages, vocabs, batch_size)#.to(device)\n",
    "           \n",
    "            # All-fake minibatches - One minibatch per source language\n",
    "            y_true = torch.full((batch_size,), real_label).long()#.to(device) # Try to fool the discriminator\n",
    "            if gan_mode == 'nonlinear':\n",
    "                for language in languages['src']:\n",
    "                    x_src = x[language]\n",
    "                    x_trans = net.generator(x_src, language)\n",
    "                    y_pred = net.discriminator(x_trans)\n",
    "                    # Loss proportional to discriminator's probability of misclassifying TP and FP\n",
    "                    loss = NLLLoss(torch.log(y_pred+0.0000001), y_true)  # Add loss for real-misclassification here\n",
    "                    loss.backward()    # Compute gradients only for discriminator\n",
    "                    loss_gen += loss\n",
    "\n",
    "                # Perform weight updates\n",
    "                for language in languages['src']:\n",
    "                    optimizers['gen'][language].step()\n",
    "                    \n",
    "            elif gan_mode == 'linear':\n",
    "                x_src = x[language]\n",
    "                x_trans = net.generator(x_src)\n",
    "                y_pred = net.discriminator(x_trans)\n",
    "                # Loss proportional to discriminator's probability of misclassifying TP and FP\n",
    "                loss = NLLLoss(torch.log(y_pred+0.0000001), y_true)# + loss_real  # Add loss for real-misclassification here\n",
    "                loss.backward()    # Compute gradients only for discriminator\n",
    "                loss_gen += loss\n",
    "                net.generator.orthogonalize()\n",
    "        \n",
    "        # Document accumulated losses per epoch\n",
    "        train_loss_gen.append(loss_gen.detach().numpy())\n",
    "        train_loss_dis.append(loss_dis.detach().numpy())\n",
    "        \n",
    "        #print('Mean: ', mean_param(net.generator.decoder))\n",
    "        print('Progress: ', loss_gen.detach().numpy(), \n",
    "                            loss_dis.detach().numpy())\n",
    "        \n",
    "        if gan_mode is 'nonlinear':\n",
    "            print('Summed abs weights Generator:', get_summed_abs_grads(net.generator).detach().numpy())\n",
    "            print('Summed abs weights Discrimi.:', get_summed_abs_grads(net.discriminator).detach().numpy())\n",
    "        elif gan_mode is 'linear':\n",
    "            print('Summed abs weights Generator:', get_summed_abs_grads(net.generator).detach().numpy())\n",
    "            print('Summed abs weights Discrimi.:', get_summed_abs_grads(net.discriminator).detach().numpy())\n",
    "        \n",
    "        # Evaluation step\n",
    "        if epoch > 0 and epoch % eval_frequency is 0:\n",
    "            evaluation(net.generator, languages, source_vocabs, eval_words, source_full_vocabs, target_full_vocabs, dictionaries, neighbors, N)\n",
    "        \n",
    "        if early_stop: # if early stopping is enabled or not\n",
    "            if es.step(loss_gen.detach()): # using the real loss of the generator for now, maybe use something else later? e.g. evaluation loss?\n",
    "                print('early stopping')\n",
    "                break  # early stop criterion is met, stop the loop now\n",
    "        \n",
    "        # Save checkpoints\n",
    "        #print(loss_real_total_g.detach().numpy(), loss_fake_total_g.detach().numpy())\n",
    "        \n",
    "#        save = checkpoint_frequency > 0 and epoch % checkpoint_frequency == 0 and \\\n",
    "#            last_loss > loss_real_total_g+loss_fake_total_g  # Provisional: save when loss of generator has improved\n",
    "#        last_loss = loss_real_total_g+loss_fake_total_g\n",
    "#        save_checkpoint({'epoch': epoch,\n",
    "#                         'model_state_dict': net.state_dict(),\n",
    "#                         'optimizer_state_dicts': \n",
    "#                             {**{lang: optimizers['gen'][lang].state_dict() for lang in languages['src']}, \n",
    "#                              **{languages['trgt'][0]: optimizers['dis']}\n",
    "#                            },\n",
    "#                         'losses': {'train_loss_real_d': train_loss_real_d[-1],\n",
    "#                                    'train_loss_fake_d': train_loss_fake_d[-1],\n",
    "#                                    'train_loss_real_g': train_loss_real_g[-1],\n",
    "#                                    'train_loss_fake_g': train_loss_fake_g[-1],},\n",
    "#                         }, save)\n",
    "\n",
    "    # Final testing\n",
    "#     testing(net.generator, languages, test_words, source_full_vocabs, target_full_vocabs, dictionaries, neighbors, N)\n",
    "    \n",
    "    # Store model\n",
    "    torch.save(net.state_dict(), final_state_path + 'final_model%d.pt' % epoch)\n",
    "    \n",
    "    # Some provision for final eval\n",
    "    evaluation(net.generator, languages, source_vocabs, eval_words, source_full_vocabs, target_full_vocabs, dictionaries, neighbors, N)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # execute only if run as a script\n",
    "    main()\n",
    "    print('Done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
